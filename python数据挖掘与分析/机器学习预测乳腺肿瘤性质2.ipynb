{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习预测乳腺肿瘤性质\n",
    "(1)\n",
    "先加载需要的module和数据，数据是csv的格式，利用pandas的read_csv函数把数据加载进来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "data=pd.read_csv('E://learnFile/ru/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 大致看看数据的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.info()\n",
    "#data.describe()\n",
    "data.shape\n",
    "data.dtypes\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把label也就是人工诊断的结果diagnosis和feature分别提取出来，方便后续数据操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "m表示恶性肿瘤\n",
    "b表示良性肿瘤\n",
    "\n",
    "'''\n",
    "diagnosis=data.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    M\n",
       "1    M\n",
       "2    M\n",
       "3    M\n",
       "4    M\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "提取特征对应的数据\n",
    "\n",
    "'''\n",
    "pred_features=data.iloc[:,2:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean           ...             radius_worst  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用五折交叉验证法，测试不同的分类算法在该数据集上的表现，本次我们只使用预测的准确率来作为评判标准。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "导入相关的模型库\n",
    "\n",
    "'''\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression  #逻辑回归分类器\n",
    "from sklearn.linear_model import SGDClassifier   #随机梯度下降分类器\n",
    "from sklearn.svm import SVC  #支持向量机分类器\n",
    "from sklearn.ensemble import RandomForestClassifier  #随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    " StratifiedKFold能够把数据集按照良恶性一定比例分成五份\n",
    " 做五折交叉验证，四份作为训练集，一份作为测试集\n",
    " 把三种分类算法在测试集上评估预测的准确率\n",
    "\n",
    "'''\n",
    "\n",
    "sfk=StratifiedKFold(y=diagnosis,n_folds=5,random_state=42,shuffle=True)\n",
    "\n",
    "'''\n",
    "接下来建立三个模型\n",
    "\n",
    "'''\n",
    "lr=LogisticRegression(random_state=42)\n",
    "SGD=SGDClassifier()\n",
    "svm=SVC(kernel='linear',C=1,random_state=42)\n",
    "RFC=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归模型交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次交叉验证准确率：0.92174\n",
      "第2次交叉验证准确率：0.93913\n",
      "第3次交叉验证准确率：0.96460\n",
      "第4次交叉验证准确率：0.97345\n",
      "第5次交叉验证准确率：0.93805\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for a,b in sfk:\n",
    "    train_x,train_y=pred_features.iloc[a,:],diagnosis[a]\n",
    "    test_x,test_y=pred_features.iloc[b,:],diagnosis[b]\n",
    "    lr.fit(train_x,train_y)\n",
    "    accuracy=lr.score(test_x,test_y)\n",
    "    i=i+1\n",
    "    print(\"第%d次交叉验证准确率：%.5f\" %(i,accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机梯度下降分类器的交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次交叉验证准确率：0.79130\n",
      "第2次交叉验证准确率：0.91304\n",
      "第3次交叉验证准确率：0.79646\n",
      "第4次交叉验证准确率：0.92920\n",
      "第5次交叉验证准确率：0.51327\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for a,b in sfk:\n",
    "    train_x,train_y=pred_features.iloc[a,:],diagnosis[a]\n",
    "    test_x,test_y=pred_features.iloc[b,:],diagnosis[b]\n",
    "    SGD.fit(train_x,train_y)\n",
    "    accuracy=SGD.score(test_x,test_y)\n",
    "    i=i+1\n",
    "    print(\"第%d次交叉验证准确率：%.5f\" % (i,accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量机模型的交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次交叉验证准确率：0.93043\n",
      "第2次交叉验证准确率：0.95652\n",
      "第3次交叉验证准确率：0.98230\n",
      "第4次交叉验证准确率：0.98230\n",
      "第5次交叉验证准确率：0.92035\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for a,b in sfk:\n",
    "    train_x,train_y=pred_features.iloc[a,:],diagnosis[a]\n",
    "    test_x,test_y=pred_features.iloc[b,:],diagnosis[b]\n",
    "    svm.fit(train_x,train_y)\n",
    "    accuracy=svm.score(test_x,test_y)\n",
    "    i=i+1\n",
    "    print(\"第%d次交叉验证准确率：%.5f\" % (i,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0次交叉验证准确率：0.93913\n",
      "第0次交叉验证准确率：0.93913\n",
      "第0次交叉验证准确率：0.97345\n",
      "第0次交叉验证准确率：0.95575\n",
      "第0次交叉验证准确率：0.96460\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for a,b in sfk:\n",
    "    train_x,train_y=pred_features.iloc[a,:],diagnosis[a]\n",
    "    test_x,test_y=pred_features.iloc[b,:],diagnosis[b]\n",
    "    RFC.fit(train_x,train_y)\n",
    "    accuracy=RFC.score(test_x,test_y)\n",
    "    print(\"第%d次交叉验证准确率：%.5f\" % (i,accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为实现代码的重复使用并更加concise，我们可以构建一个类，将上面的过程包装起来使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class winsconBC:\n",
    "    def __init__(self,data_y,method,rand_seed=42,Nfolds=3,shuffled=True):\n",
    "        from sklearn.cross_validation import StratifiedKFold\n",
    "        self.data=data_y\n",
    "        self.clf=method\n",
    "        self.Rseed=rand_seed\n",
    "        self.Nfolds=Nfolds\n",
    "        self.shuffle=shuffled\n",
    "        self.classifier=method\n",
    "        self.sfk=StratifiedKFold(y=self.data,n_folds=self.Nfolds,random_state=self.Rseed,shuffle=self.shuffle)\n",
    "    def classify(self):\n",
    "        accuracy=list()\n",
    "        for tr,ts in self.sfk:\n",
    "            train_x,train_y=pred_features.iloc[tr,:],diagnosis[tr]\n",
    "            test_x,test_y=pred_features.iloc[ts,:],diagnosis[ts]\n",
    "        if(self.classifier=='logistic'):\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            lr=LogisticRegression(random_state=self.Rseed)\n",
    "            lr.fit(train_x,train_y)\n",
    "            accuracy.append(lr.score(test_x,test_y))\n",
    "        if(self.classifier=='SGD'):\n",
    "            from sklearn.linear_model import SGDClassifier\n",
    "            SGD=SGDClassifier(random_state=self.Rseed)\n",
    "            SGD.fit(train_x,train_y)\n",
    "            accuracy.append(SGD.score(test_x,test_y))\n",
    "        if(self.classifier=='SVM'):\n",
    "            from sklearn.svm import SVC\n",
    "            svm=SVC(kernel='linear',C=1,random_state=self.Rseed)\n",
    "            svm.fit(train_x,train_y)\n",
    "            accuracy.append(svm.score(test_x,test_y))\n",
    "        if(self.classifier=='randomforest'):\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            rm=RandomForestClassifier()\n",
    "            rm.fit(train_x,train_y)\n",
    "            accuracy.append(rm.score(test_x,test_y))\n",
    "        return np.array(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h/HjIaO20DfwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5d1ac82780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.bar(np.arange(4),np.array([np.mean(winsconBC(data_y=diagnosis,method=i,Nfolds=5).classify()) for i in [\"SGD\",'logistic','SVM',\"randomforest\"]]))\n",
    "plt.xticks(np.arange(4),(\"SGD\",'logistic','SVM',\"randomforest\"))\n",
    "plt.axhline(0.95,c=\"r\") ## 加一条accuracy=0.95的基准曲线做参考\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置模型的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    http://blog.sina.com.cn/s/blog_7103b28a0102w08u.html\n",
    "    sklearn-SGD\n",
    "    随机梯度下降算法\n",
    "    1.1 概述\n",
    "        注意：在进行分类前确保训练数据进行过序列置换操作（permute,shuffle），或者在生成模型时使用shuffle=True参数设置，使得每次迭代后数据进行过序列置换。这个的意思就是样本数据在完成每次迭代后，其顺序被重新排列。\n",
    "    GDClassifier类支持以不同损失函数进行随机梯度下降进行分类，大致使用过程如下：    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "X=[[0.,0.],[1.,1.]]\n",
    "y=[0,1]\n",
    "clf=SGDClassifier(loss='hinge',penalty=\"l2\")\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2.,2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    关于损失函数，可以通过参数loss设置。可选的损失函数包括：\n",
    "\n",
    "    ·        loss=\"hinge\": (soft-margin) linear Support Vector Machine,\n",
    "\n",
    "    ·        loss=\"modified_huber\": smoothed hinge loss,\n",
    "\n",
    "    ·        loss=\"log\": logistic regression,\n",
    "\n",
    "    ·        loss=\"squared_loss\": Ordinary least squares,\n",
    "\n",
    "    ·        loss=\"huber\": Huber loss for robust regression,\n",
    "\n",
    "    ·        loss=\"epsilon_insensitive\": linear Support Vector Regression.\n",
    "\n",
    "    关于惩罚项，可以通过penalty参数设置，可选的包括：\n",
    "\n",
    "    ·        penalty=\"l2\": L2 norm penalty on coef_.\n",
    "\n",
    "    ·        penalty=\"l1\": L1 norm penalty on coef_.\n",
    "\n",
    "    ·        penalty=\"elasticnet\": Convex combination of L2 and L1;(1 - l1_ratio) * L2 + l1_ratio * L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载相关module和数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "data=pd.read_csv('E://learnFile/ru/data.csv')\n",
    "diagonsis=data.diagnosis\n",
    "predi_features=data.iloc[:,2:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class winsconBC:\n",
    "    def __init__(self,data_y,method,rand_seed=42,Nfolds=3,shuffled=True):\n",
    "        from sklearn.cross_validation import StratifiedKFold\n",
    "        self.data=data_y\n",
    "        self.clf=method\n",
    "        self.Rseed=rand_seed\n",
    "        self.Nfolds=Nfolds\n",
    "        self.shuffle=shuffled\n",
    "        self.classifier=method\n",
    "        self.sfk=StratifiedKFold(y=self.data,n_folds=self.Nfolds,random_state=self.Rseed,shuffle=self.shuffle)\n",
    "    def classify(self):\n",
    "        accuracy=list()\n",
    "        for tr,ts in self.sfk:\n",
    "            train_x,train_y=predi_features.iloc[tr,:],diagnosis[tr]\n",
    "            test_x,test_y=predi_features.iloc[ts,:],diagnosis[ts]\n",
    "            \n",
    "        if(self.classifier=='logistic'):\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            lr=LogisticRegression(random_state=self.Rseed)\n",
    "            lr.fit(train_x,train_y)\n",
    "            accuracy.append(lr.score(test_x,test_y))\n",
    "        if(self.classifier=='SGD'):\n",
    "            from sklearn.linear_model import SGDClassifier\n",
    "            SGDclf=SGDClassifier(loss=\"log\",n_iter=1000,learning_rate=\"optimal\")  ### 手动设置参数，详见sklearn官网\n",
    "            SGD.fit(train_x,train_y)\n",
    "            accuracy.append(SGD.score(test_x,test_y))\n",
    "        if(self.classifier=='SVM'):\n",
    "            from sklearn.svm import SVC\n",
    "            svmClf=SVC(kernel=\"linear\",C=1)  ### 这里设置kernal=linear,不再是默认的rbf\n",
    "            svm.fit(train_x,train_y)\n",
    "            accuracy.append(svm.score(test_x,test_y))\n",
    "        if(self.classifier=='randomforest'):\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            rm=RandomForestClassifier()\n",
    "            rm.fit(train_x,train_y)\n",
    "            accuracy.append(rm.score(test_x,test_y))\n",
    "        return(np.array(accuracy))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBhnuktQgw12SGvT/YaSKr87Thp0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5d1ae21128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.bar(np.arange(4),np.array([np.mean(winsconBC(data_y=diagnosis,method=i,Nfolds=5).classify()) for i in [\"SGD\",'logistic','SVM',\"randomforest\"]]))\n",
    "plt.xticks(np.arange(4),(\"SGD\",'logistic','SVM',\"randomforest\"))\n",
    "plt.axhline(0.95,c=\"r\") ## 加一条accuracy=0.95的基准曲线做参考\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 贝叶斯方法的提出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提出者：托马斯·贝叶斯\n",
    "\n",
    "    贝叶斯方法思考问题的模式：先验分布P (A) + 样本信息B =后验分布(P(A|B))， 这种思考模式意味着，新观察到的样本信息将修正人们以前对事物的认知。换言之，在得到新的样本信息之前，人们对A的认知是先验分布P(A) ，在得到新的样本信息后，人们对A的认知为P(A|B) 。\n",
    "\n",
    "    通俗理解就好比是人类刚开始时对大自然只有少得可怜的先验知识，但随着不断是观察、实验获得更多的样本、结果，使得人们对自然界的规律摸得越来越透彻。所以，贝叶斯方法既符合人们日常生活的思考方式，也符合人们认识自然的规律。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有关的定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    条件概率（又称后验概率）指利用贝叶斯公式，结合调查等方式获取了新的附加信息，对先验概率进行修正得到的更符合实际的概率。就是事件A在另外一个事件B已经发生条件下的发生概率。条件概率表示为P(A|B)，读作“在B条件下A的概率”， P(A|B) =P(AB)/P(B)。\n",
    "\n",
    "    联合概率也叫乘法公式，是指两个任意事件的乘积的概率，或称之为交事件的概率。A与B的联合概率表示为P(AB)。\n",
    "\n",
    "    先验概率是指根据历史的资料或主观判断所确定的各事件发生的概率。该类概率没能经过试验证实，属于检验前的概率，所以称之为先验概率。先验概率一般分为两类，一是客观先验概率，是指利用过去的历史资料计算得到的概率；二是主观先验概率，是指在无历史资料或历史资料不全的时候，只能凭借人们的主观经验来判断取得的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 接着，考虑一个问题：P(A|B)是在B发生的情况下A发生的可能性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    首先，事件B发生之前，我们对事件A的发生有一个基本的概率判断，称为A的先验概率，用P(A)表示；\n",
    "        其次，事件B发生之后，我们对事件A的发生概率重新评估，称为A的后验概率，用P(A|B)表示；\n",
    "        类似的，事件A发生之前，我们对事件B的发生有一个基本的概率判断，称为B的先验概率，用P(B)表示；\n",
    "        同样，事件A发生之后，我们对事件B的发生概率重新评估，称为B的后验概率，用P(B|A)表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 公式P(B|A)=P(A|B)*P(B)/P(A)\n",
    "    这个定理解决了现实生活里面经常遇到的问题：已知某条件概率，如何得到两个事件交换后的概率，也就是 已知P(A|B)的情况下如何求得P(B|A)的概率。\n",
    "    朴素贝叶斯分类有一个限制条件，就是特征属性必须有条件独立或基本独立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92173913,  0.92173913,  0.95575221,  0.94690265,  0.95575221])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nbClf=GaussianNB()\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(nbClf,pred_features,diagnosis,cv=5,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层感知机    也就是全连接神经网络\n",
    "    神经网络的机制：把输入层的特征变量先乘以权重后求和加上一个偏置项，通过一个activation function 进行非线性转换，将这些非线性变换的结果再次作为输入层，以同样的方法再次进入下一个隐藏层，直到最后的输出层，该过程称为前向传播（forward propagation），再利用后向传播算法（back propagation）和梯度下降更新权重，不断最小化损失函数，直至得到最优解（或者局部最优解）。\n",
    "\n",
    "    神经网络结构的隐藏层部分可以自由搭建，就像乐高积木一样可以一层一层拼接起来，隐藏层可以10层，可以20层，甚至上百层上千层，只要算力足够，现在深度学习的发展趋势是网络层数越来越多，所以得名Deep Learning。每一个隐藏层的神经元个数也可自由设置，可以说神经网络的构建没有严格意义上的规则可循，但是网络结构常常决定最后的算法效果。CNN和RNN正是通过对基础神经网络架构的各项要素（各层输入变量、隐藏层的维度、非线性转换方式等方面）进行改造完善，近年来在图像识别、语音识别、自然语言等领域表现出令人惊叹的效果，证明了神经网络这种层级网络结构在捕捉数据背后隐藏规律方面的巨大威力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1)keras第一种方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92173913,  0.92173913,  0.90265487,  0.85840708,  0.88495575])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf=MLPClassifier(activation=\"relu\",batch_size=20,hidden_layer_sizes=(30,30,30,30),max_iter=2000,random_state=42,learning_rate_init=0.001)\n",
    "cross_val_score(cv=5,estimator=clf,n_jobs=-1,X=predi_features,y=diagnosis,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2)Keras第二种方式\n",
    "    遇到的一个问题：Keras训练神经网络的时候报错IndexError: indices are out-of-bounds，也就是索引超出边界\n",
    "    解决方案：\n",
    "    Keras expects numpy arrays not pandas, so you need to convert all of the data that you are feeding into Keras APIs.. not just y_train and y_test\n",
    "\n",
    "    So:\n",
    "\n",
    "    x_train = x_train.values\n",
    "    y_train = y_train.values\n",
    "    x_test = x_test.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "    Or\n",
    "\n",
    "    x_train = numpy.asarray(x_train)\n",
    "    y_train = numpy.asarray(y_train)\n",
    "    x_test = numpy.asarray(x_test)\n",
    "    y_test = numpy.asarray(y_test)\n",
    "\n",
    "    Or\n",
    "\n",
    "    x_train=x_train.as_matrix().astype(int)\n",
    "    y_train=y_train.as_matrix().astype(int)\n",
    "    x_test =x_test.as_matrix().astype(int)\n",
    "    y_test =y_test.as_matrix().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "data=pd.read_csv('E://learnFile/ru/data.csv')\n",
    "diagnosis=data['diagnosis']\n",
    "pred_features=data.iloc[:,2:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[data['diagnosis']=='M','diagnosis']=1\n",
    "data.loc[data['diagnosis']=='B','diagnosis']=0\n",
    "x_train =data.iloc[:,2:32].as_matrix().astype(int)\n",
    "y_train =data.iloc[:,1].as_matrix().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)\n",
    "len(y_train)\n",
    "y_train.astype(int)\n",
    "x_train.shape\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=30, units=20)`\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=20, units=20)`\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=20, units=1)`\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\keras\\models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/569 [>.............................] - ETA: 4s"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras.layers.core import Dense,Activation\n",
    "model=Sequential()#建立模型\n",
    "model.add(Dense(input_dim=30,output_dim=20))\n",
    "model.add(Activation('relu'))#用relu作为激活函数\n",
    "model.add(Dense(input_dim=20,output_dim=20))\n",
    "model.add(Activation('relu'))#用relu作为激活函数\n",
    "model.add(Dense(input_dim=20,output_dim=1))\n",
    "model.add(Activation('sigmoid'))#输出分类0或1\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam')\n",
    "\n",
    "#训练模型，学习一千次yp=model.predict_classes(x).reshape(len(y))  #分类预测\n",
    "model.fit(x_train,y_train,nb_epoch=1000,batch_size=16,verbose=0)\n",
    "#预测分类\n",
    "yp = model.predict_classes(x_train).reshape(len(y_train)) #分类预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD0CAYAAABuOhhTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x806070c0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #导入作图库\n",
    "from sklearn.metrics import confusion_matrix #导入混淆矩阵函数\n",
    "def cm_plot(y, yp):\n",
    "    cm = confusion_matrix(y, yp) #混淆矩阵\n",
    "    plt.matshow(cm, cmap=plt.cm.Greens) #画混淆矩阵图，配色风格使用cm.Greens，更多风格请参考官网。\n",
    "    plt.colorbar() #颜色标签\n",
    "    for x in range(len(cm)): #数据标签\n",
    "        for y in range(len(cm)):\n",
    "            plt.annotate(cm[x,y], xy=(x, y), horizontalalignment='center', verticalalignment='center')\n",
    "    plt.ylabel('True label') #坐标轴标签\n",
    "    plt.xlabel('Predicted label') #坐标轴标签\n",
    "    return plt\n",
    "cm_plot(y_train,yp).show() #显示混淆矩阵可视化结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评价分类器的指标\n",
    "    前面几次的交叉验证，我们都利用scikit-learn里的accuracy指标来评价分类器在测试集上的性能。\n",
    "    \n",
    "    但是accuracy作为分类器评价指标存在一定局限性，假如我们面临一个二分类问题，测试数据集A（size=100）里有90个样例分类标签是0，还有10个实际分类标签是1。我们构建一个不借助任何机器学习算法的分类器（暂取名zero classifier），无论什么测试数据，zero classifier一直预测分类标签是0。这样的分类器在前述测试数据集A上的表现如何？它也可以达到90%的准确率，与前面人工神经网络的预测水平相当，这说明accuracy在面对比较skewed的数据集时作分类器的评价指标会存在问题。\n",
    "\n",
    "    其实机器学习领域并非只有accuracy一个评价指标，常用其他指标还有confusion matrix，precision，recall，F1-score，ROC curve等，通过乳腺肿瘤的数据集，我们来对这些指标逐一解读。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、confusion matrix （混淆矩阵）\n",
    "    首先看confusion matrix，中文翻译为混淆矩阵,sklearn里的函数confusion_matrix可以为我们返回混淆矩阵。混淆矩阵的大小为n*n，n表示所有类别的数量，每行表示实际类别数量，每列表示预测出来的类别数量，通过矩阵的形式可以看到分类器在每个类别的预测成绩。\n",
    "\n",
    "    还是以二分类（0，1）问题举例，下面这个混淆矩阵的解读方法：实际分类为0的数据有50个，其中分类器正确预测了其中48个，把2个错分到类别1，实际分类为1的数据是58个，分类器正确预测了51个，把7个错分到了0类别。在混淆矩阵中，我们希望主对角线（左上至右下）上的数字越大好，副对角线（左下到右上）上的数字越小越好。 \n",
    "       48    2\n",
    "       7     51\n",
    "    利用confusion_matrix看看前面几个分类器表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for logistical classifier is:\n",
      "[[71  1]\n",
      " [ 6 36]]\n",
      "confusion matrix for SVM classifier is:\n",
      "[[70  2]\n",
      " [ 7 35]]\n",
      "confusion matrix for randomForest classifier is:\n",
      "[[71  1]\n",
      " [ 6 36]]\n",
      "confusion matrix for MLP classifier is:\n",
      "[[70  2]\n",
      " [ 6 36]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "cut=StratifiedShuffleSplit(n_splits=1,random_state=42,test_size=0.2)\n",
    "for a,b in cut.split(X=pred_features,y=diagnosis):\n",
    "    train_x,train_y=pred_features.iloc[a,:],diagnosis[a]\n",
    "    test_x,test_y=pred_features.iloc[b,:],diagnosis[b]\n",
    "    \n",
    "'''\n",
    "逻辑回归\n",
    "\n",
    "''' \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logClf=LogisticRegression()\n",
    "test_pred=logClf.fit(train_x,train_y).predict(test_x)\n",
    "print('confusion matrix for logistical classifier is:')\n",
    "print(confusion_matrix(test_y,test_pred))\n",
    "\n",
    "'''\n",
    "支持向量机\n",
    "\n",
    "'''\n",
    "from sklearn.svm import SVC\n",
    "svmClf=SVC(kernel='linear',C=1)\n",
    "test_pred_svm=svmClf.fit(train_x,train_y).predict(test_x)\n",
    "print('confusion matrix for SVM classifier is:')\n",
    "print(confusion_matrix(test_y,test_pred_svm))\n",
    "\n",
    "'''\n",
    "随机森林\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfClf=RandomForestClassifier()\n",
    "test_prediction_rf=rfClf.fit(train_x,train_y).predict(test_x)\n",
    "print('confusion matrix for randomForest classifier is:')\n",
    "print(confusion_matrix(test_y,test_prediction_rf))\n",
    "\n",
    "\n",
    "'''\n",
    "神经网络\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "MLPclf=MLPClassifier(activation=\"relu\",batch_size=80,\n",
    "                  hidden_layer_sizes=(30,30,30,15,55,15,15,30),\n",
    "                  max_iter=2000,random_state=42,learning_rate_init=0.001)\n",
    "test_prediction_MLP=MLPclf.fit(train_x,train_y).predict(test_x)\n",
    "print('confusion matrix for MLP classifier is:')\n",
    "print(confusion_matrix(test_y,test_prediction_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precision ，recall and F1-score.\n",
    "    https://www.zhihu.com/question/30643044\n",
    "    precision 表示精准程度，在分类器预测的阳性中，有多大比例是真阳性，recall表示灵敏程度，即分类器能将所有真阳性中多大比例的样本预测出来，一般来讲，两者之间存在一个折衷，精准度非常高，那灵敏度就相对不那么高，反之亦然。而从F1_score的计算公式来看，它把两个指标综合起来，要precision和recall都相对较高时，才能得到一个较高的F1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for SVM is 0.95\n",
      "recall for SVM is 0.83\n",
      "F1_score for SVM is 0.89\n",
      "F1_score for randomforest is 0.91\n",
      "F1_score for logisticRegression is 0.91\n",
      "F1_score for MLP is 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "\n",
    "## 注意这里要把label标签转换成0，1变量而非字符串\n",
    "\n",
    "print(\"precision for SVM is %.2f\" % (precision_score(test_y=='M',test_pred_svm==\"M\")))\n",
    "print(\"recall for SVM is %.2f\" %(recall_score(test_y=='M',test_pred_svm==\"M\")))\n",
    "\n",
    "print(\"F1_score for SVM is %.2f\" %(f1_score(test_y=='M',test_pred_svm==\"M\")))\n",
    "print(\"F1_score for randomforest is %0.2f\" %(f1_score(test_y=='M',test_prediction_rf==\"M\")))\n",
    "print(\"F1_score for logisticRegression is %.2f\" %(f1_score(test_y=='M',test_pred==\"M\")))\n",
    "print(\"F1_score for MLP is %.2f\" %(f1_score(test_y=='M',test_prediction_MLP==\"M\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAEzCAYAAAAGisbbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xlc1NX+x/HXF1xwRXOBSgVcwAXEBU3T0DLNXEvLMjU1\nzbTSftfc07ZrLmm5pkbm0uI1tTKzUttcr97ENLPcF9wScccFEDi/P0bJygUROAO8n4/HPGBmvvM9\nH2cK3pxzvuc4xhhEREREJGN42C5AREREJDtT2BIRERHJQApbIiIiIhlIYUtEREQkAylsiYiIiGQg\nhS0RERGRDHTDsOU4zgzHcY46jrPlGs87juNMdBxnl+M4mx3HqZH+ZYqIiIhkTanp2ZoFNL3O8w8C\nFS7degBTb70sERERkezhhmHLGLMSOHGdQ1oDHxiXdUARx3FuT68CRURERLKy9JizdSdw4Ir7By89\nJiIiIpLj5crMxhzH6YFrqJECBQrUrFixYmY2L5KtREfDH3/A7beDjw/ExUFUlOu5oCDX16go1+O+\nvuDtDadPw5Ej4OUFfn6uY7Zvd33183M9Hh0Np05BkSI6r86r8/qVMa7zHoFTp6FIYYNPiSTXeQ/l\nAmMICkgAY4g6nJu4BA98b0vAu0Aip896cuREHrxyJ+FX8gIYw/ZDBV3nLX4Or1yJRJ/24tT5PBTJ\nF49PofPEXfQk6kQhV73Fj7vOe8qbuMRc+BaIxTvPBU7HeXHkQiG8PC7iV9B1zPYztwMGv3wxeHkk\nEB1XhFOJBSjieRafPCeIS8pNVLyv67x597nOm3AHcSYPvp4xeDtnOJ1UiCPJJfBy4vBzDrjOayq4\n6iUKL+KJxodTeFOE0/gQTRx5icL1pgWxw/X+UoY4vPAlGm9OcxpvjuCDF3H4sd/1/hLo9ufNw3ny\ncJCjQLLrP4djxpgSpIGTmr0RHcfxBxYbY4Kv8ty7wHJjzH8u3d8ONDTG/HG9c4aFhZnIyMi01CyS\nJTRs6Pr67ruuH/Jjx8LixdCiBfTr5/ph/swzrmOWL3d97dEDduyAF1+Eli3hyy/hrbcgMBAiIq5+\nXpF0ZwwkJUFi4p9fr3fLrsckJ9v+JNxHrlyum6fnn99f65YNjtkZFUW1hg25cOECj7Rpw0tDhlCt\nZs0NxpiwNL196fARLAKedxxnLnAXcPpGQSsni4iAOXNc39/KL9iM+sWt86bveSWLMcb1C9bdQ0BG\nH5OUZPuTcB9X+0Xt5kEh3Y/x8ADHsf1JZLgDBw6w4aefeOihhyhfogT9+vXj8ccfp1KlSrd87huG\nLcdx/gM0BIo7jnMQeAXIDWCMmQZ8DTQDdgHnga63XFU21qABrF0Le/farkQy2uVQdlm/fq7bZUFB\n/zzm7yGtZUvX7XrnTTdXCxnuFgIy4xhx8fBw/xCQ0cd4euaIkJHT7dmzh1GjRjFr1iwKFChAkyZN\nyJ8/P6+99lq6tZGqYcSMkN2HEW/UUyJu5HLIcPcQkNHHWPpZ4HYuhwx3DgGZcYxChmRze/bs4fXX\nX+ejjz7C09OTbt26MXDgQPwuT9z7G8dxrA4jCn8OD+bYIaTkZEhIcM06jY9P/dcbPZcZgUMh40+5\nc9v/JW/zGE9PV9gSkWwrOTkZDw8PoqOjmTdvHr1796Z///7ccccdGdamwlY6uf12uHjxz/s3GkJK\nN0lJaQ8z6RmMEhIy4B+Xidw9BGTGMQoZIpKN/fzzzwwfPhxfX1+mTJlC3bp1OXToEEWLFs3wthW2\nbtHlHq0XX4Q1a27hRMZAbCwcP37124kTV3/8zJl0+7fcsrx5XTcvr39+f7Nf8+aFPHmu3tOS3oFD\nIUNEJNtat24dw4cP56uvvsLb25t+V/R8ZEbQAoWtWxYZCStWuMLWNcXFwZIlrkvXrhemruwaSy3H\nubkAcyvh53rH5MmjOR4iIuJW3njjDYYOHcptt93G8OHDef755/H29s70OhS2UikiwtWJdLVlAK46\nRys5GVavhg8/hPnzXavm3Uj+/FCs2M3dvL3VMyMiIgIYY/juu+/w8/MjMDCQVq1akSdPHnr16kXB\nggWt1aWwdQ2XhwcvX004ZIjr8RvOu9q+3RWwPvroz2WLAWrWdK37cL3g5OWVYf8eERGR7MoYw1df\nfcXw4cP53//+R69evZgyZQohISGEhITYLk9h61rmzHEND142aBAULuz6/h/rIx09CnPnukLWlctZ\nlC4NHTtCp06QDouiiYiIyF998cUXvPbaa2zcuBF/f3+mTZtGly5dbJf1FwpbV7hyBfCrXU34Fxcu\nwKJFroC1ZMmfKy4XLgyPPOIKWOHhGuITERFJZ5eXbwBYtGgRZ8+eZebMmXTo0IHcuXNbru6fcnzY\nuvJqwhtKToaVK10Ba8GCP68EzJXLtVppx47QqhXky5ehNYuIiOREFy9eZM6cOYwYMYIPP/yQ2rVr\n8/bbb1OwYEE8PT1tl3dNOT5sXXk14dW2RgFg61ZXwPr4Y9i//8/Ha9Vy9WA9/jiUSNNG4CIiInID\n8fHxzJ49m1GjRrF3716qVavGxUtX8Nu4uvBm5YiwdaNNha96NeHWra7eq08/hV9++fNxPz9XD1bH\njlCxYmaULyIikmMlJiZStWpVduzYQe3atZk4cSLNmzfHyULLDWXrsLV9+00cbAz8+qsrYC1Y4Apb\nl3l7w6OPunqx6tfXPCwREZEMdO7cOT777DM6duxIrly5eOGFFyhfvjyNGzfOUiHrsiy9EXVEhGub\nnJYt/zq5/XJPleO4Vlv4+2T3FMbAhg2u3qsFC2DXrj+fK1oUHnrINdm9USPX4p0iIiKSYc6cOcM7\n77zD22+/zbFjx1i/fj1hYWna+znd5diNqOfMcS26ftV5VriC1hNPXOWJixddiWzsWNi378/HS5SA\nhx92BayGDV1bxYiIiEiGio2N5a233mLChAmcOnWKZs2aMXToULcJWrcqS4etwMA/v7/a5PZ/9GgZ\n4+rBGjLkz14sX19o29YVsOrXd11ZKCIiIhnu8hIOSUlJTJgwgYYNGzJ06FBq1qxpu7R0laWTxVUn\ntl/LypUwYAD873+u+4GBMHKka6hQc7BEREQyzR9//MHYsWNZu3Ytq1evpkiRIuzatYtixYrZLi1D\nZMmUERHhGuVr2DAVB//2m6vLq0EDV9Dy8YGpU2HLFmjTRkFLREQkkxw4cIDnn3+egIAAJkyYQPny\n5Tl37hxAtg1akEV7tho0gLVrYe/e6xx06BC88grMnOlajLRAAVfPVt++YHEzShERkZzou+++o1mz\nZgB07tyZQYMGUa5cOctVZY4sFbYur/beooUrQ13V6dMwejSMH+/aUidXLujZE15+2dWrJSIiIpli\n+/btREdHEx4ezt13302fPn3o06cPZcqUsV1apspSY2hnzrhG/67KGJgyBcqVc83FunDBNen999/h\nnXcUtERERDLJli1bePzxx6lUqRK9e/fGGEP+/PkZO3ZsjgtakEXC1uU5Wi1bwrFjV9kUGlxLxD/3\nHBw/Dvfc4xpnnD8fKlTI7HJFRERypM2bN9OmTRtCQkL46quvGDhwIN9++22WXIg0PWWJYcQ5c1z7\nF17XO++4vr7yiuuWwz9YERGRzGKMwXEc1q9fzw8//MDLL7/MCy+8wG233Wa7NLeQpVeQT7F7N5Qv\nD15eronx+nBFREQy3IoVKxg+fDgtW7akT58+JCQkcOHChSyxOfTNupUV5N16GPHy8GGPHqk4EOCx\nxxS0REREMpAxhmXLlhEeHk7Dhg359ddfKVCgAAB58uTJlkHrVrnlMOLlPQ9vv921s851XbgAM2a4\nvu/VK8NrExERycm6du3K7NmzufPOO5k4cSLdu3cnX758tstya24Zti7vebhmzbX3PQQgIQEefdQ1\na75GDahdO9NqFBERyQmSk5NZuHAh9913H0WKFKFdu3bUrVuXLl26kDdvXtvlZQluOYwYGAhVqtzg\noKQk6NgRvvoKihWDDz7QpHgREZF0kpSUxJw5cwgJCaFt27bMnj0bgGbNmvHMM88oaN0Et+zZuuGe\nh8nJ0L27a2mHwoVh6dJUpDMRERG5keTkZD744ANGjBjBzp07qVKlCnPmzKFdu3a2S8uy3DJsXZcx\n0KcPzJoF+fPD119DNtsdXEREJLNdXr7BcRwiIiIoWLAgn376KQ899BAe2kf4lrjlu3fNTaaNgUGD\nXGtq5c0LixZBvXqZXJ2IiEj2ceHCBSZNmkTFihU5evQojuOwaNEiNmzYQJs2bRS00kHWegffeAPe\nfNO13+H8+dCoke2KREREsqSzZ88yduxYAgIC6NOnDz4+Ppw4cQKA4sWL5/hV39OTWw4jvvvuVR4c\nPx6GDQMPD/jooxtcpigiIiLXEhMTQ+XKlTl27Bj3338/8+bNIzw83HZZ2ZZbhq2goL898N578K9/\nub6fPt21eKmIiIik2okTJ1i1ahWtW7emRIkSPPvsszRt2pS6devaLi3bc8uwNXas62u/frgW3Xrm\nGdcDEydC167W6hIREclqjh49yrhx45g8eTIJCQkcOnSI4sWL89prr9kuLcdwyzlbixe7bixcCE8+\n6ZoYP3Ik9O5tuzQREZEsITo6mr59++Lv78/o0aNp0aIFkZGRFC9e3HZpOY5b9my1aAFs3+4aLkxK\ngpdecl2FKCIiItd1eQmHY8eOMXnyZNq3b8+QIUMI+sccHcksbhm2+tVeCS83dW3H88IL8O9/2y5J\nRETEre3evZtRo0YRHx/PBx98QJUqVTh48CAlS5a0XVqO51bDiBER0LDmGbo22s/2C6Vdq8SPG6dt\neERERK5h27ZtPPnkkwQFBfHhhx9SpEgRjDEAClpuwq3CVo86m2m6dRx7E0uxolZ/mDZNQUtEROQa\npk+fTuXKlfn000954YUX2Lt3LxMnTtQaWW7GfYYRY2LgwQcZdOEwg1q3di1a6ulpuyoRERG3smHD\nBry8vKhSpQqNGjVi4MCB9O3blxIlStguTa7BPXq2jIEuXehx+BV6+HwBc+dC7ty2qxIREXEba9eu\npVmzZoSFhaUs2xAQEMDIkSMVtNyce4St8ePh66/ZkasyOwKagJeX7YpERETcwqpVq7j//vu5++67\nWb9+PSNGjGD69Om2y5KbYH8YMTKSiP47uJ0WvDggF9RR0BIRkZzt8gR3x3FYuHAhW7ZsYezYsfTs\n2ZMCBQpYrk5ulnP5A81sYWFhJvKHH6BGDRruns7F28uw5nBZK7WIiIi4A2MMixcvZvjw4QwfPpzG\njRtz+vRp8uTJQ758+WyXl6M5jrPBGBOWltfaHUbs2RN27yaw2HGqPFjGaikiIiK2JCcns2DBAqpX\nr06rVq04evQo8fHxAHh7eytoZXH2hhGPHSNiQw3meKxk+X99IND+iKaIiEhmM8YQHh7OmjVrCAwM\nZNasWTzxxBPk1oVi2UaqhhEdx2kKTAA8genGmFF/e94b+AgogyvAjTXGzLzeOcM8PU3B5O9ZQUMs\njWSKiIhYcfHiRT7//HMeeeQRPDw8eO+99yhYsCDt2rXDU8seuaUMHUZ0HMcTeAd4EKgMtHccp/Lf\nDnsO+N0YEwo0BN5yHCfPdU+cnMy7rb9h27a0lC0iIpL1xMfHM23aNCpUqMBjjz3GsmXLAHj66adp\n3769glY2lZo5W7WBXcaYPcaYBGAu0PpvxxigkONasrYgcAJIvNGJg4Y+ivbFFBGR7C4+Pp6JEydS\nrlw5evXqha+vL4sXL+aBBx6wXZpkgtSErTuBA1fcP3jpsStNBioBh4FfgReMMcl/P5HjOD0cx4l0\nHCcSYOxHvowdm6a6RURE3N7lqTrJycmMHDmScuXK8e2337J27VqaN2+ubXVyiPS6GvEBYBNwB1AN\nmOw4TuG/H2SMiTDGhF0e81y8ypvFi9OpAhERETdx+vRp3njjDe666y4uXrxIvnz52LhxIytWrOD+\n++9XyMphUhO2DgGlr7hf6tJjV+oKfGZcdgF7gYo3OnGLe07TokVqSxUREXFvJ06c4OWXX8bPz4+h\nQ4fi4+PDyZMnAfD19bVcndiSmvUW1gMVHMcJwBWyHgee+Nsx+4FGwCrHcXyAIGDP9U66nUBa3nOK\noLalbr5qERERN/Pzzz/ToEEDzp49S5s2bRg6dCjVq1e3XZa4gRuGLWNMouM4zwNLcS39MMMY85vj\nOD0vPT8N+Dcwy3GcXwEHGGiMOXa9856l0C0XLyIiYtPhw4fZsWMHDRs2JCQkhC5duvDMM88QHBxs\nuzRxI/a263EcExkZCTVrWmlfREQkraKiohg9ejTvv/8+JUuWZN++fVq2IZvLutv1iIiIZCF79+6l\ne/fulC9fnunTp9O5c2dWrFihoCXXZW2PnCi0F6KIiGQNxhgcx+Hnn3/mo48+omfPngwYMIDSpUvf\n+MWS41kLW3F42WpaREQkVTZv3szw4cMJCQlh2LBhPPzww+zbt09XFspNsTaM6Eu0raZFRESuKzIy\nkoceeojQ0FCWLFmSsim0h4eHgpbcNGs9W96cttW0iIjINQ0ePJhRo0ZRpEgRXn31Vfr06UPRokVt\nlyVZmLWwdRpvW02LiIikMMawYsUKKlasiK+vLw888ACFCxfmueeeo3Dhf2yGInLTrA0jHsHHVtMi\nIiIYY1i6dCnh4eHce++9vPPOOwA0bNiQwYMHK2hJurEWtryIs9W0iIjkcF9++SV33XUXTZs2JSoq\nismTJ/PSSy/ZLkuyKWvDiH7st9W0iIjkQJeXbwCYMmUKx44dIyIigs6dO5MnTx7L1Ul2pkVNRUQk\nW0tMTOTjjz+mWrVq7N27F4BZs2axY8cOnn76aQUtyXDWwtZ2Am01LSIiOcDFixeZMWMGlSpVomPH\njiQlJRETEwOAj48PuXJZG9yRHEb/pYmISLZz7tw5QkJC2Lt3L9WrV+ezzz6jdevWeHhoQEcyn8U5\nW1G2mhYRkWzo/Pnz/PDDD7Ro0YICBQrw5JNPUqtWLZo1a5YyV0vEBmthy4t4W02LiEg2Ehsby9Sp\nU3nrrbc4evQou3btoly5crz66qu2SxMBLM7ZitY6WyIicgvOnDnD8OHD8ff3Z+DAgYSGhrJixQrK\nlStnuzSRv7AWtk5pBXkREUkDYwwAJ0+e5PXXX+fuu+9m3bp1LFu2jPDwcMvVifyTtWHEItobUURE\nbkJ0dDRvvfUWe/bsYcGCBfj5+bFnzx5KlSpluzSR67LWs+VDtK2mRUQkCzl06BD/93//R0BAAG+9\n9RZ58uQhISEBQEFLsgRrPVtx5LXVtIiIZBELFy7kscceIykpiU6dOjF48GACA7VOo2Qt1sJWlFdF\nCAiw1byIiLipXbt2ce7cOUJDQ7n77rvp1q0b/fv3J0C/MySLsre6W65ccNtt1poXERH3snXrVjp2\n7EhQUBB9+/YFoGTJkkyZMkVBS7I0a2ErKMhWyyIi4k42b97Mo48+SpUqVVi4cCF9+/bl448/tl2W\nSLrRdj0iImLVF198wdKlSxk8eDD/+te/KF68uO2SRNKVc3m9ksxWokSYiYmJtNK2iIjYs2bNGoYP\nH85TTz3Fo48+SmxsLImJiRQtWtR2aSLX5DjOBmNMWFpea20YMS7OVssiIpLZjDH8+OOP3HfffdSv\nX58NGzZw4cIFAAoVKqSgJdmatWFEX19bLYuISGZ77LHHmD9/Prfffjtvv/02PXr0oECBArbLEskU\n1sKWt3brERHJtowxfP311zRp0oTcuXPTokULGjZsyFNPPYWXl5ft8kQylbVhxNParUdEJNtJTk5m\n/vz5VKtWjRYtWjBv3jwAnnzySZ599lkFLcmRrIWtI0dstSwiIuktKSmJjz76iODgYNq1a0d8fDwf\nfPABjz32mO3SRKyzNoyoP25ERLIPYwyvvvoq+fLlY+7cuTzyyCN4enraLkvELVgLW35+tloWEZFb\nFRcXx8yZM5k1axY//vgj+fPn58cff+TOO+/Ew8Pe5iQi7kj/R4iISKqdP3+e8ePHU65cOZ599lk8\nPDw4cmleSOnSpRW0RK7CWs/W9u22WhYRkbTYvXs3d999N0ePHqVBgwZ88MEH3HfffTiOY7s0Ebem\nP0FEROSaTp06xfLlywEICAigTZs2rFy5kuXLl9OoUSMFLZFU0JwtERH5h2PHjjF+/HgmTZqE4zgc\nPnyY/PnzM3XqVNuliWQ51nq2dDWiiIj7iY6OZsCAAfj7+/PGG2/QuHFjli9fTv78+W2XJpJlWevZ\nio621bKIiFzLli1beOutt3j88ccZMmQIVapUsV2SSJZnLWydOmWrZRERuWzfvn2MGjWKIkWKMGrU\nKO677z727NmDn+Z6iKQba8OIRYrYallERHbu3MlTTz1FhQoVmDFjBgkJCQA4jqOgJZLOrPVs+fjY\nallEJGcbN24c/fr1I0+ePDz77LP079+fUqVK2S5LJNuyFrbi4my1LCKS8/zyyy8ULVqUMmXKUL9+\nffr27cuLL76Ir6+v7dJEsj1rw4hRUbZaFhHJOdavX0+rVq2oVq0ao0aNAqBWrVqMGTNGQUskk2hR\nUxGRbGjNmjU0bdqU2rVrs2bNGl5//XVGjBhhuyyRHMnaMGJQkK2WRUSyv8mTJ/Pzzz8zevRoevXq\nRaFChWyXJJJjqWdLRCSLM8bwzTffUL9+fTZv3gzA+PHj2bdvHwMGDFDQErEsVWHLcZymjuNsdxxn\nl+M4g65xTEPHcTY5jvOb4zgrbnROzdkSEbk1ycnJfPHFF9SuXZtmzZpx4MABjhw5AoCPj49WfRdx\nEzccRnQcxxN4B2gMHATWO46zyBjz+xXHFAGmAE2NMfsdxyl5o/PqakQRkbRLTEykbt26REZGUrZs\nWaZPn06nTp3IkyeP7dJE5G9S07NVG9hljNljjEkA5gKt/3bME8Bnxpj9AMaYozc6qS6CERG5OYmJ\niSxduhSAXLly8dBDD/Hhhx+yfft2unXrpqAl4qZSE7buBA5ccf/gpceuFAgUdRxnueM4GxzHefJG\nJ/X2Tn2RIiI5WUJCAu+//z4VK1akadOmREZGAvDSSy/RsWNHcuWydq2TiKRCek2QzwXUBJoDDwDD\nHMcJ/PtBjuP0cBwn0nGcyP37z6RT0yIi2VNcXBxTp06lQoUKdO/enSJFirBw4UJq1KhhuzQRuQmp\n+XPoEFD6ivulLj12pYPAcWPMOeCc4zgrgVBgx5UHGWMigAiAQoXCTFqLFhHJCWJjY+nXrx+hoaFM\nmzaNpk2b4jiO7bJE5CalJmytByo4jhOAK2Q9jmuO1pW+ACY7jpMLyAPcBYy73km9vG6+WBGR7Cw2\nNpapU6eyevVqvvjiC0qUKMGvv/5KQECAQpZIFnbDYURjTCLwPLAU2ArMM8b85jhOT8dxel46Ziuw\nBNgM/ARMN8Zsud55tam8iIjLqVOneP311/Hz82PgwIEkJCRw5oxrqkXZsmUVtESyOMcYO6N5YWFh\n5vIkTxGRnGrFihW0atWKM2fO0LJlS4YOHUrt2rVtlyUif+M4zgZjTFhaXmttBfnt2221LCJi15Ej\nR9i4cSMA1atXp3Xr1mzcuJFFixYpaIlkQ9Z6tgoVCjOxserZEpGc4+DBg4wZM4aIiAgCAwPZtGmT\nhghFsogs2bOlOVsiklPs27ePnj17Uq5cOaZMmUL79u1ZsGCBgpZIDmFtJTxdjSgiOcXixYuZOXMm\nXbt2ZdCgQfj7+9suSUQykbVhxNKlw8yBAxpGFJHs57fffuONN96gUaNGdOvWjQsXLnD8+HFKlSpl\nuzQRSaMsOYx46pStlkVEMsbGjRtp27YtwcHBLFq0iNOnTwOQL18+BS2RHMzaMGKRIrZaFhFJf336\n9GHSpEkULlyYoUOH8sILL1C8eHHbZYmIG7AWtnx8bLUsIpI+Vq9eTfXq1SlQoAD169enRIkS9O7d\nmyL6a1JErmBtGDEuzlbLIiJpZ4zh+++/p2HDhtxzzz28//77ALRr145hw4YpaInIP1gLW1FRtloW\nEbl5xhi+/vpr6tWrx/3338/OnTsZP3483bt3t12aiLg5a8OIIiJZzUsvvcTJkyeZOnUqXbt2JW/e\nvLZLEpEswFrPVlCQrZZFRG4sKSmJTz75hPr163Py5Ekcx+Hzzz9n586d9OzZU0FLRFLNWtgSEXFH\niYmJfPjhhwQHB/P4449z4sQJ9u/fD4C/vz+5c+e2XKGIZDXWhhE1Z0tE3E1MTAx16tRhz549VK1a\nlXnz5tG2bVs8PPR3qYiknbWwpasRRcQdxMXFsX79eu655x6KFy/OAw88QNOmTWnRooVCloikC2vb\n9VSoEGZ27tR2PSJix/nz53n33XcZM2YMJ0+eZP/+/ZQoUcJ2WSLiprLkdj3e3rZaFpGcLDY2ltGj\nR+Pv70/fvn2pWLEiX3/9tVZ7F5EMYy1sXdoyTEQkU+3YsYNBgwZRs2ZNVq9ezQ8//MC9996L4zi2\nSxORbMranK0jR2y1LCI5ybFjxxg3bhxnz55lwoQJ1KxZk23bthGk9WdEJJNY69ny8rLVsojkBEeO\nHKFfv374+fkxcuRIYmJiSE5OBlDQEpFMZa1ny8/PVssikt199NFHdO/enYsXL9K+fXuGDBlC5cqV\nbZclIjmUtusRkWxh7969GGMoW7YsYWFhPPHEEwwePJgKFSrYLk1Ecjhrw4jbt9tqWUSykx07dtC1\na1cqVKjAkCFDAKhYsSIzZsxQ0BIRt6CeLRHJkrZs2cKIESP45JNPyJMnD88//zz9+/e3XZaIyD9o\nzpaIZElTpkxh0aJF9OvXj759++Lj42O7JBGRq9LViCKSJfzvf/+jRYsWrF69GoBXX32VqKgoRo8e\nraAlIm7NWtiKjrbVsohkJStXrqRJkybUqVOHtWvXcujQIQBKlixJsWLFLFcnInJj1oYRT52y1bKI\nZAXGGFq2bMlXX31FyZIlefPNN+nVqxcFCxa0XZqIyE2xFraKFLHVsoi4K2MMK1asoEGDBjiOQ4MG\nDWjSpAndu3cnf/78tssTEUkTa8OImmIhIpclJyfz+eefExYWxr333su3334LQP/+/enTp4+Clohk\nadbCVlx/WofnAAAgAElEQVScrZZFxF0kJSUxd+5cQkNDadOmDWfOnGHGjBnce++9tksTEUk31oYR\no6JstSwi7uL8+fM899xz+Pr68vHHH9OuXTty5dLyfyKSveinmohkmoSEBGbPns3ChQtZtGgRhQoV\nYs2aNQQGBuLhYa2jXUQkQ1n76RYUZKtlEclscXFxvPPOO5QvX54ePXpw9OhRjh49Cri21lHQEpHs\nTD/hRCRDbd68mYCAAJ5//nnKlCnDkiVL+Omnn7j99tttlyYikimshS3N2RLJvs6cOcPGjRsBCAwM\nJDw8nB9//JFVq1bxwAMP4DiO5QpFRDKPY4yx0nChQmEmNjbSStsikjFOnjzJxIkTmTBhAoULF2bX\nrl2a8C4i2YLjOBuMMWFpea21ni1fX1sti0h6O3bsGEOGDMHPz49XX32V8PBwFixYoKAlIoLFsOXt\nbatlEUlvS5YsYdSoUTz44IP88ssvLFy4kLCwNP0BKCKS7Vj7s/P0aVsti8itOnDgAG+++SYVKlSg\nT58+PP7444SFhVGxYkXbpYmIuB1rPVtHjthqWUTSas+ePfTo0YNy5coxbdo0Dh8+DECuXLkUtERE\nrsFaz5aXl62WRSQtRowYwcsvv4ynpyfdu3dn4MCB+Pn52S5LRMTtWQtb+hkt4v62bNnCHXfcwW23\n3UZoaCi9e/emf//+3HHHHbZLExHJMrSoqYj8w88//0ybNm0ICQlh4sSJADRv3pxx48YpaImI3CRr\nYWv7dlsti8i1rFu3jhYtWlCzZk1++OEHhg0bRu/evW2XJSKSpaUqbDmO09RxnO2O4+xyHGfQdY6r\n5ThOouM4j6RfiSKSWQYNGsS6desYPnw4UVFRvP766xQrVsx2WSIiWdoNw5bjOJ7AO8CDQGWgveM4\nla9x3GhgWWoa1pwtEbuMMXz77bc0btw45arCmTNnsm/fPl566SW8tRieiEi6SE3PVm1glzFmjzEm\nAZgLtL7Kcb2BT4GjqWlYVyOK2GGMYfHixdStW5cmTZqwdetWdu3aBUBAQAAFCxa0XKGISPaSmrB1\nJ3DgivsHLz2WwnGcO4GHgampbTg6OrVHikh6OX/+PGFhYbRs2ZLo6GimTZvG7t27CQ8Pt12aiEi2\nlV4T5McDA40xydc7yHGcHo7jRDqOExkTczGdmhaR60lKSmLt2rUA5M+fn3r16jFz5kx27NjBM888\nQ968eS1XKCKSvaVmna1DQOkr7pe69NiVwoC5juMAFAeaOY6TaIxZeOVBxpgIIAKgdOkwk9aiReTG\nLl68yJw5cxgxYgS7du1i586dlC1bNmUpBxERyRyp6dlaD1RwHCfAcZw8wOPAoisPMMYEGGP8jTH+\nwALg2b8Hrb/z8UljxSJyXfHx8URERBAUFESXLl3Inz8/8+bNw9/f33ZpIiI50g17towxiY7jPA8s\nBTyBGcaY3xzH6Xnp+WlpaTguLi2vEpEbiYqKolevXoSFhTFx4kSaN2/OpV5nERGxwDHGzmheoUJh\nJjY20krbItnJuXPnmDZtGjt37mTaNNffPps3byYkJEQhS0QknTiOs8EYE5aW12q7HpEs6syZM4wc\nORJ/f3/69evH7t27iY+PB6Bq1aoKWiIibsJa2AoKstWySNb3zTff4Ofnx5AhQ6hduzb//e9/+fbb\nb3VloYiIG1LPlkgWERMTw86dOwEIDg6mUaNGREZG8tVXX1G3bl3L1YmIyLVYC1tRUbZaFsla/vjj\nD1588UX8/f157rnnAChdujQLFiygZs2alqsTEZEbSc06WxlCVyOKXN+BAwcYPXo006dPJzExkSee\neIIhQ4bYLktERG6StbDl62urZZGsYerUqURERNC5c2cGDRpEuXLlbJckIiJpYG0Y0dvbVssi7mn7\n9u107tyZr7/+GoB+/fqxa9cu3nvvPQUtEZEszFrYOn3aVssi7mXLli08/vjjVKpUifnz57N3714A\nbrvtNsqUKWO5OhERuVXWhhGPHLHVsoj76NGjB++99x4FCxZk4MCB/Otf/6JkyZK2yxIRkXRkrWfL\ny8tWyyJ2rV+/nqSkJABCQkJ4+eWXiYqKYuTIkQpaIiLZkLWw5ednq2URO1asWEHjxo2pXbs28+fP\nB6B379689tpr3HbbbZarExGRjKJFTUUykDGGZcuWER4eTsOGDfn1118ZM2YMLVq0sF2aiIhkEmtz\ntrZvt9WySOa5ePEi3bp1wxjDxIkT6d69O/ny5bNdloiIZCJrYUskO0pOTubzzz9n5syZfPrpp+TN\nm5clS5ZQvnx57VsoIpJDac6WSDpISkpizpw5hISE8Mgjj7Bjxw6iLu1JVaVKFQUtEZEcTFcjityi\nffv2UalSJTp06IDjOMyZM4etW7cSGBhouzQREXED1sJWdLStlkVuXXx8PJs2bQJcm0JXrVqVTz/9\nlM2bN9O+fXs8PT0tVygiIu7CMcZYabhQoTATGxtppW2RtLpw4QLTp0/nzTffJC4ujqioKPLnz2+7\nLBERyWCO42wwxoSl5bXWeraKFLHVssjNO3v2LGPHjiUgIIA+ffrg7+/Pxx9/rCsLRUTkhqxdjejj\nY6tlkZu3fPly+vfvz/33388nn3xCgwYNbJckIiJZhLWwFRdnq2WRGztx4gQTJkwgX758DBo0iObN\nm7NhwwZq1KhhuzQREclirA0jXroqXsStHD16lMGDB+Pn58frr7/Otm3bAHAcR0FLRETSRNv1iFzy\n3nvv4e/vz+jRo2nevDmbN29m1qxZtssSEZEsztowYlCQrZZF/rR//37y5s2Lj48PQUFBPProowwZ\nMoQg/QcqIiLpRD1bkiPt3r2bp59+mvLlyzNixAgAwsPDmT17toKWiIikK2s9W5qzJTZs27aNESNG\nMGfOHHLlysUzzzzDiy++aLssERHJxnQ1ouQogwcPZtmyZbzwwgv069eP22+/3XZJIiKSzVkbRvT1\ntdWy5CQbNmygTZs27NixA4Bx48axb98+3nrrLQUtERHJFNbClre3rZYlJ1i7di3NmjUjLCyMH3/8\nka1btwLg7+9PiRIlLFcnIiI5ibVhxNOnbbUs2VlSUhLNmzdn6dKlFC9enBEjRvDcc89RuHBh26WJ\niEgOZS1sHTliq2XJbowxbNy4kRo1auDp6UmVKlVo3LgxPXv2pECBArbLExGRHM4xxlhpuESJMBMT\nE2mlbckejDEsXryY4cOH89NPP7Fx40aqVatmuywREcmGHMfZYIwJS8trrc3Z8vOz1bJkdcnJySxY\nsIDq1avTqlUrjh49yrvvvkulSpVslyYiIvIP1oYRRdIqOjqaDh064O/vz6xZs3jiiSfInTu37bJE\nRESuylrY2r7dVsuS1Vy8eJGPPvqIVatWMWPGDG6//XbWrFlD9erV8fT0tF2eiIjIdWm7HnFb8fHx\nvPvuuwQGBvLUU0+xadMmTl+6jDUsLExBS0REsgTN2RK3tG7dOsqVK0fPnj3x8fFh8eLFbNiwAW8t\n0CYiIlmMtWFELy9bLYu7Onv2LIcPHyYwMJAKFSoQEhLCrFmzaNSoEY7j2C5PREQkTayFrehoWy2L\nuzl9+jSTJk1i3LhxBAQEsH79eooVK8Y333xjuzQREZFbZi1snTplq2VxFydOnGD8+PFMnDiR06dP\n07x5c1566SX1YomISLZibc5WkSK2WhZ3MWPGDP7973/TqFEjNmzYwOLFi6lbt67tskRERNKVtRXk\nw8LCTGSkVpDPSQ4fPsyYMWOoW7cu7dq14+zZs+zbt4/g4GDbpYmIiFzXrawgb20YMS7OVsuS2aKi\nohg9ejTvv/8+SUlJKVcUFixYUEFLRESyPWthKyrKVsuSmYYNG8aoUaNwHIeuXbsycOBAypYta7ss\nERGRTKNFTSXdbdu2jbhLXZf+/v707NmT3bt38+677ypoiYhIjmMtbAUF2WpZMsrmzZtp164dlStX\nZubMmQB069aNSZMmUbp0acvViYiI2JGqsOU4TlPHcbY7jrPLcZxBV3m+g+M4mx3H+dVxnP86jhOa\n/qWKu4qMjOShhx4iNDSUJUuWMGjQIB555BHbZYmIiLiFG87ZchzHE3gHaAwcBNY7jrPIGPP7FYft\nBRoYY046jvMgEAHcdb3zas5W9mCMoVOnThw5coRXX32VPn36ULRoUdtliYiIuI3UTJCvDewyxuwB\ncBxnLtAaSAlbxpj/XnH8OqDUjU6qqxGzJmMMK1asYOLEicyePZtChQoxb948/Pz8KFy4sO3yRERE\n3E5qhhHvBA5ccf/gpceupRtw1X1WHMfp4ThOpOM4kfnynUl9lWKdMYalS5cSHh7Ovffey9q1a9m2\nbRsAISEhCloiIiLXkK4T5B3HuRdX2Bp4teeNMRHGmDBjTFiZMvrlnFUcO3aMu+66i6ZNmxIVFcXk\nyZPZu3cvtWrVsl2aiIiI20vNMOIh4MpLyUpdeuwvHMepCkwHHjTGHL/RSU+fTm2JYkNycjK///47\nwcHBFCtWjDJlyvD000/TuXNn8uTJY7s8ERGRLOOG2/U4jpML2AE0whWy1gNPGGN+u+KYMsAPwJN/\nm791TYUKhZnYWG3X424SExP55JNPeOONN9i/fz9RUVEUK1bMdlkiIiJW3cp2PTccRjTGJALPA0uB\nrcA8Y8xvjuP0dByn56XDXgaKAVMcx9nkOM4NU5SXV1rKlYxy8eJFZsyYQaVKlejYsSMeHh5Mnz6d\nItoxXERE5JZoI2oB4L///S/16tWjevXqDBs2jNatW+PhoQ0GREREIItuRC12nT9/nunTp3Py5Ele\neeUV7r77blatWkW9evVwHMd2eSIiItmGtbC1fbutlnO2s2fPMnXqVMaOHcvRo0dp0qQJycnJeHh4\nUL9+fdvliYiIZDsaJ8pBPvvsM/z8/BgwYAChoaGsWLGCpUuXarhQREQkA1nr2fLzs9VyznL8+HHi\n4+O54447CAgIoG7dugwdOpQ6derYLk1ERCRHsNaloasRM1Z0dDQDBgzAz8+PQYNce4dXr16dxYsX\nK2iJiIhkIms9W9HRtlrO3g4dOsSYMWOIiIggPj6exx57jIEDr7qgv4iIiGQCa2Hr1ClbLWdvL7/8\nMrNnz6ZTp04MHjyYwMBA2yWJiIjkaNbW2SpdOswcOKB1tm7Vrl27GDlyJM8++yw1a9bkwIEDJCYm\nEhAQYLs0ERGRbCNDV5DPKD4+tlrOHrZu3UrHjh0JCgpizpw5/PLLLwCULl1aQUtERMSNWBtGjIuz\n1XLWZoyhc+fOfPTRR+TPn5++ffvy4osv4uvra7s0ERERuQprPVtRUbZazpp+//13ABzHoVSpUgwe\nPJh9+/YxZswYBS0RERE3Zm3OVqFCYSY2VnO2bmTNmjUMHz6cJUuWsHz5cho0aGC7JBGRHOHixYsc\nPHiQOA3F5CheXl6UKlWK3Llz/+XxLLk3YlCQrZbdnzGG5cuX8+9//5sff/yREiVKMGrUKKpXr267\nNBGRHOPgwYMUKlQIf39/7RmbQxhjOH78OAcPHkzX+c/aiNoNxcbG0rp1awoWLMjbb79Njx49KFCg\ngO2yRERylLi4OAWtHMZxHIoVK0ZMTEy6ntda2NKcrT8ZY/jyyy/5/PPPmTFjBoULF2bZsmVUq1YN\nLy21LyJijYJWzpMRn7m1CfIaAofk5GTmz59PtWrVaN26NStXruTw4cMA1KlTR0FLRETSlb+/P8eO\nHbvl88yaNYsSJUpQrVo1qlWrxpNPPpkO1V3dvn37mDNnToadPzNYC1s5/QK6rVu3EhwcTLt27YiP\nj+eDDz5g+/bt3HnnnbZLExERN2SMITk52XYZKR577DE2bdrEpk2b+OCDD1L9usTExJtqR2HrFnh7\n22rZnoSEBHbt2gVAmTJl8PX1Ze7cufz222906tSJXLk0hU5ERP60b98+goKCePLJJwkODqZbt26E\nhYVRpUoVXnnllZTj/P39eeWVV6hRowYhISFs27YNgOPHj9OkSROqVKlC9+7duXIFgrfffpvg4GCC\ng4MZP358SnsVK1akS5cuBAYG0qFDB7777jvq1atHhQoV+Omnn65b76ZNm6hTpw5Vq1bl4Ycf5uTJ\nkwA0bNiQ//u//yMsLIwJEyYQExND27ZtqVWrFrVq1WLNmjUArFixIqW3rHr16sTGxjJo0CBWrVpF\ntWrVGDduXLq+v5nGGGPlVr58TZNTXLhwwUyZMsWUKVPGVKhQwSQmJtouSUREbuD333//8w5kzO0G\n9u7daxzHMWvXrjXGGHP8+HFjjDGJiYmmQYMG5pdffjHGGOPn52cmTpxojDHmnXfeMd26dTPGGNO7\nd2/z2muvGWOMWbx4sQFMTEyMiYyMNMHBwebs2bMmNjbWVK5c2fz8889m7969xtPT02zevNkkJSWZ\nGjVqmK5du5rk5GSzcOFC07p1a2OMMTNnzjTFixc3oaGhJjQ01MyYMcMYY0xISIhZvny5McaYYcOG\nmRdeeMEYY0yDBg1Mr169Uv5d7du3N6tWrTLGGBMVFWUqVqxojDGmRYsWZvXq1cYYY2JjY83FixfN\njz/+aJo3b35Tn92t+stnfwkQadKYeax1pRw5YqvlzHP+/HkiIiIYM2YMhw8fpk6dOgwbNgwPD2sd\niiIiksX4+flRp04dAObNm0dERASJiYn88ccf/P7771StWhWANm3aAFCzZk0+++wzAFauXJnyffPm\nzSlatCgAq1ev5uGHH0650r1NmzasWrWKVq1aERAQQEhICABVqlShUaNGOI5DSEgI+/btS6nrscce\nY/LkySn3T58+zalTp1LWg+zcuTOPPvroX46/7LvvvktZrBvgzJkznD17lnr16tG3b186dOhAmzZt\nKFWqVDq8g/ZZC1s5Ye733Llz+de//kWDBg344IMPuO+++3Rli4hIVmRpAXAgJRDt3buXsWPHsn79\neooWLUqXLl3+suBq3rx5AfD09LzpeVFXunweAA8Pj5T7Hh4et3TeK5cwSk5OZt26df+4EGzQoEE0\nb96cr7/+mnr16rF06dI0t+dOrHWx+PnZajnjnDp1iuHDhzN79mwAOnTowKpVq1i+fHnKXwYiIiJp\ncebMGQoUKIC3tzfR0dF88803N3xNeHh4yuTyb775JmUO1T333MPChQs5f/48586d4/PPP+eee+65\npfq8vb0pWrQoq1atAuDDDz+85q4nTZo0YdKkSSn3N23aBMDu3bsJCQlh4MCB1KpVi23btlGoUCFi\nY2NvqTbbNJ6VDo4dO8bQoUPx8/Nj2LBhrFu3DnD9dVC/fn3L1YmISHYQGhpK9erVqVixIk888QT1\n6tW74WteeeUVVq5cSZUqVfjss88oU6YMADVq1KBLly7Url2bu+66i+7du6fLLiWzZ8+mf//+VK1a\nlU2bNvHyyy9f9biJEycSGRlJ1apVqVy5MtOmTQNg/PjxBAcHU7VqVXLnzs2DDz5I1apV8fT0JDQ0\nNMtOkNfeiLdo0qRJDB48mHPnztG2bVuGDh1KtWrVbJclIiK3aOvWrVSqVMl2GWLB1T77W9kbUT1b\naXDo0KGULs2SJUvSqlUrtmzZwoIFCxS0RERE5C80Z+sm7Nu3j549e1K2bFneeecdwHV1xZw5c6hS\npYrl6kRERMQd6WrEVNi5cycjR47kww8/xMPDg65du/7lElYRERGRa7EWtqKjbbV88zp37szGjRt5\n9tln6d+/f7ZZ90NEREQynrVhxFOnbLV8Y7/88gsdOnQgJiYGgIiICPbu3cuECRMUtEREROSmWAtb\nRYrYavna1q9fT6tWrahWrRqLFy9OWfcjODgY35y+c7aIiIikibWw5eNjq+V/On/+PE2bNqV27dqs\nWbOG119/naioKBo3bmy7NBERycEKFiyY5td27979L1vi/N2sWbM4fPjwTR1fokQJqlWrRsWKFd1u\nzavIyEj69Olju4yrsjZn64odBqwwxrBz504CAwPJnz8/RYsWZdSoUTz77LMUKlTIbnEiIiK3aPr0\n6dd9ftasWQQHB3PHHXek6nj4cz/E48ePExQUxCOPPELp0qVvqc7LmzXf6r7BYWFhhIWlaRmsDGet\nZysqyk67xhi++eYb6tevT3BwMAcOHADgP//5DwMHDlTQEhERt2OMoX///gQHBxMSEsInn3wCuPYY\nfPbZZ6lYsSKNGzemWbNmLFiwAICGDRsSGRlJUlISXbp0SXntuHHjWLBgAZGRkXTo0IFq1apx4cKF\nlOMBlixZQo0aNQgNDaVRo0b/qKdYsWKUL1+eP/74A4CYmBjatm1LrVq1qFWrFmvWrEl5vHHjxlSp\nUoXu3bvj5+fHsWPH2LdvH0FBQTz55JMpv4uXLVtG3bp1qVGjBo8++ihnz54FXPslVq5cmapVq9Kv\nXz8A5s+fT3BwMKGhoYSHhwOwfPlyWrRoAcCJEyd46KGHqFq1KnXq1GHz5s0AvPrqqzz11FM0bNiQ\nsmXLMnHixAz5vP7hcqLM7FvBgjVNZkpKSjILFy40YWFhBjBlypQxU6ZMMRcuXMjUOkREJGv4/fff\n/3K/QQPXbds21/0xY1z3x4xx3d+27c9jLnv6adf9RYtc9xctct1/+unU1VCgQAFjjDELFiww999/\nv0lMTDRHjhwxpUuXNocPHzbz5883Dz74oElKSjJ//PGHKVKkiJk/f/6lehuY9evXm8jISHP//fen\nnPPkyZN/ef7Pf5/r/tGjR02pUqXMnj17jDHGHD9+3BhjzMyZM81zzz1njDEmKirKhIaGpvwObd++\nvVm1alXKcxUrVjTGGPPcc8+ZESNGGGOM+eabbwxgYmJizN69e43jOGbt2rXGGGNiYmLMPffcY86e\nPWuMMWbUqFHmtddeM8eOHTOBgYEmOTn5L7UHBwebgwcP/uWxH3/80TRv3twYY8zzzz9vXn31VWOM\nMd9//70JDQ01xhjzyiuvmLp165q4uDgTExNjbrvtNpOQkPCP9/3vn70xxgCRJo2Zx9owYlBQ5ra3\nbds2HnroIcqWLcv06dPp1KkTefLkydwiRERE0mD16tW0b98eT09PfHx8aNCgAevXr2f16tU8+uij\neHh44Ovry7333vuP15YtW5Y9e/bQu3dvmjdvTpMmTa7b1rp16wgPDycgIACA2267LeW5Tz75hJUr\nV7Jt2zYmT56M16VFM7/77ru/zPc6c+YMZ8+eZfXq1Xz++ecANG3alKJFi6Yc4+fnR506dVLa/P33\n31P2e0xISKBu3bp4e3vj5eVFt27daNGiRUrPVb169ejSpQvt2rWjTZs2V32/Pv30UwDuu+8+jh8/\nzpkzZwBo3rw5efPmJW/evJQsWZLo6OgMX2nAWtjKaImJicydO5etW7fyxhtvULlyZb7//nvCw8PJ\nlSvb/rNFRCSDLF/+1/v9+rlulwUF/fOYiIi/3m/Z0nXLTEWLFuWXX35h6dKlTJs2jXnz5jFjxow0\nnevynK3IyEiaNGlCq1at8PX1JTk5mXXr1qWEr9QoUKBAyvfGGBo3bsx//vOffxz3008/8f3337Ng\nwQImT57MDz/8wLRp0/jf//7HV199Rc2aNdmwYUOq282bN2/K956eniQmJqb6tWmV7fZGTEhI4P33\n36dixYp06tSJr7/+mvj4eMCVbhW0REQkq7nnnnv45JNPSEpKIiYmhpUrV1K7dm3q1avHp59+SnJy\nMtHR0Sz/e9oDjh07RnJyMm3btmX48OH8/PPPABQqVChln98r1alTh5UrV7J3717ANf/p78LCwujU\nqRMTJkwAoEmTJkyaNCnl+ctLJ9WrV4958+YBsGzZMk6ePHnVf1+dOnVYs2YNu3btAuDcuXPs2LGD\ns2fPcvr0aZo1a8a4ceP45ZdfANi9ezd33XUXr7/+OiVKlEiZf33l+/Xxxx8DrrlcxYsXp3Dhwtd4\ndzNetkoey5cvp3Pnzuzfv5+aNWuycOFCWrZsectXOIiIiNj08MMPs3btWkJDQ3EchzfffBNfX1/a\ntm3L999/T+XKlSldujQ1atTA29v7L689dOgQXbt2JTk5GYCRI0cC0KVLF3r27Em+fPlYu3ZtyvEl\nSpQgIiKCNm3akJycTMmSJfn222//UdPAgQOpUaMGQ4YMYeLEiTz33HNUrVqVxMREwsPDmTZtGq+8\n8grt27fnww8/pG7duvj6+lKoUKGUye9Xtjlr1izat2+f0kEyfPhwChUqROvWrYmLi8MYw9tvvw1A\n//792blzJ8YYGjVqRGhoKCtWrEg53+WJ8FWrViV//vzMnj07HT6FtHNcc74yX1hYmLl81cOtOH/+\nPCdPnuTOO+9k165dPPXUUwwePJimTZviOE46VCoiIjnR1q1bqVSpku0ybujs2bMULFiQ48ePp6wX\n6S4LccfHx+Pp6UmuXLlYu3YtvXr1Sun1cmdX++wdx9lgjEnT2hJZtmcrNjaWKVOm8NZbb1GnTh0W\nLVpE+fLlWblype3SREREMk2LFi04deoUCQkJDBs2zG2CFsD+/ftp164dycnJ5MmTh/fee892SVZk\nubB16tQpJk2axPjx4zlx4gQPPPAAAwYMsF2WiIiIFVebp+UuKlSowMaNG22XYV2WC1tvvPEGY8eO\npWXLlgwdOpTatWvbLklERETkmtx+5viRI0cYMGBAysS3F198kY0bN7Jo0SIFLRERyVC25jWLPRnx\nmbttz9bBgwcZM2YMERERJCQkUKxYMRo0aICvr69bjUeLiEj25OXlxfHjxylWrJguuMohjDEcP378\nptYLSw23DFsDBgxg/PjxGGPo1KkTgwcPpkKFCrbLEhGRHKRUqVIcPHiQmJgY26VIJvLy8kr3FeVT\nFbYcx2kKTAA8genGmFF/e9659Hwz4DzQxRjz880UsmfPHvz9/fHw8KBw4cJ069aNgQMH4u/vfzOn\nERERSRe5c+dO2bJG5FbccM6W4ziewDvAg0BloL3jOJX/dtiDQIVLtx7A1NQW8Ntvv/HEE09QoUIF\nvmJ+15gAAAS7SURBVPzySwCGDh3K1KlTFbREREQky0tNz1ZtYJcxZg+A4zhzgf9v735C46jDMI5/\nH6gBjWKKq1KipVX8e7BQlRQpUvWg7aUIOYhioQgi/sFADhUDepCA3kRESihFvOjBFK1QFUG0Qo3/\noG1Si01VKIlCaRUDDSghr4dZwxKz2d9uMrM7+nxgYHfnl+QND7u8Ozs7707g+5o1O4G3qlOxxyT1\nSFoXEb/W+6Wzs7P09/czOjpKd3c3g4OD9PX1reBfMTMzM+s8Kc1WL1A7dGgKWNwVLbWmF6jbbE1O\nTjI9Pc3Q0BADAwNUKpXEks3MzMzKo9AT5CU9TvYxI8CfMzMzE8PDwwwPDxdZhq2OCnCu3UVYS5xd\nuTm/cnN+5XVTqz+Y0mxNA9fW3L+m+liza4iIEWAEQNK3rc4YsvZzfuXl7MrN+ZWb8ysvSS0PdE65\nqOk3wA2SNkrqAh4CDi5acxDYpcwW4I/lztcyMzMz+79oeGQrIuYkPQ18THbph/0RcULSE9X9e4FD\nZJd9OE126Yfd+ZVsZmZmVh5J52xFxCGyhqr2sb01twN4qsm/PdLkeusszq+8nF25Ob9yc37l1XJ2\n8twnMzMzs/x0/CBqMzMzszLLvdmS9ICkHySdlvTcEvsl6bXq/uOSNuddk6VJyO6Rambjko5I2tSO\nOm1pjfKrWXenpDlJ/UXWZ8tLyU/SNklHJZ2Q9HnRNdrSEl47L5f0gaRj1ex8nnOHkLRf0llJE3X2\nt9azRERuG9kJ9T8C1wFdwDHg1kVrdgAfAgK2AF/lWZO3Vc3uLmBt9fZ2Z9c5W0p+Nes+JTsns7/d\ndXtLzw/oIZvksb56/6p21+0tObvngVeqt68EfgO62l27twC4G9gMTNTZ31LPkveRrYVRPxHxF/DP\nqJ9aC6N+ImIM6JG0Lue6rLGG2UXEkYj4vXp3jOz6atYZUp57AM8Ao8DZIouzhlLyexg4EBFnACLC\nGXaGlOwCuEySgEvJmq25Ysu0pUTEYbI86mmpZ8m72ao3xqfZNVa8ZnN5jKzbt87QMD9JvcCDNDE4\n3gqT8vy7EVgr6TNJ30naVVh1tpyU7F4HbgF+AcaBZyNivpjybIVa6lkKHddj/02S7iFrtra2uxZr\nyqvAnoiYz95gW8msAW4H7gMuBr6UNBYRp9pbliW4HzgK3AtcD3wi6YuImGlvWZaXvJutVRv1Y4VL\nykXSbcA+YHtEnC+oNmssJb87gHeqjVYF2CFpLiLeK6ZEW0ZKflPA+Yi4AFyQdBjYBLjZaq+U7HYD\nL0d2EtBpST8DNwNfF1OirUBLPUveHyN61E95NcxO0nrgAPCo3013nIb5RcTGiNgQERuAd4En3Wh1\njJTXzveBrZLWSLoE6ANOFlyn/VtKdmfIjkgi6WqyAcc/FVqltaqlniXXI1vhUT+llZjdC8AVwBvV\noyNz4QGrHSExP+tQKflFxElJHwHHgXlgX0Qs+XV1K07ic+8l4E1J42TfatsTEefaVrQtkPQ2sA2o\nSJoCXgQugpX1LL6CvJmZmVmOfAV5MzMzsxy52TIzMzPLkZstMzMzsxy52TIzMzPLkZstMzMzsxy5\n2TIzMzPLkZstMzMzsxy52TIzMzPL0d+2IAcwbqggUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5d1ae0d828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_scores=cross_val_predict(rfClf,train_x,train_y,cv=3,method=\"predict_proba\")\n",
    "y_scores_logit=cross_val_predict(logClf,train_x,train_y,cv=3,method=\"predict_proba\")\n",
    "\n",
    "y_scores_rf = y_scores[:, 1]\n",
    "y_scores_log=y_scores_logit[:, 1]\n",
    "fpr_log,tpr_log,t_log=roc_curve(train_y=='M',y_scores_log)\n",
    "\n",
    "fpr,tpr,thres=roc_curve(train_y=='M',y_scores_rf)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(fpr,tpr,linewidth=2,c=\"r\",label=\"randomForest\")\n",
    "plt.plot(fpr_log,tpr_log,\"b:\",label=\"logisticRegression\")\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.axis([0,1,0,1])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the AUC for logisticRegression is 0.9893\n",
      "the AUC for randomForest is 0.9773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('the AUC for logisticRegression is %.4f'%(roc_auc_score(train_y==\"M\", y_scores_log)))\n",
    "print('the AUC for randomForest is %.4f'%(roc_auc_score(train_y==\"M\", y_scores_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 调参 \n",
    "参数搜索的方法对前面几种分类器模型参数进行调整，以提升分类器的类别预测效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    一 、SVM支持向量机\n",
    "\n",
    "        在支持向量机函数中，kernal可以选择’linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’，如果kernal选择为rbf、poly、 sigmoid，超参数gamma也可以调整。\n",
    "\n",
    "\n",
    "    二、Logistic回归分类器\n",
    "\n",
    "        logistic regression里面可以调整的超参数有：\n",
    "\n",
    "        penalty：正则惩罚项：使用L1还是L2惩罚项，默认一般是L2.\n",
    "\n",
    "        C : 正则化程度的倒数，C越小，正则化程度越强\n",
    "\n",
    "        solver：优化算法选择，有四个：newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’， 默认采取是liblinear的优化算法，该方法对规模小的数据集效果较好，数据集规模较大的时候sag的速度更快. 面对多分类变量问题的时候，只有 ‘newton-cg’, ‘sag’ 和’lbfgs’能处理多分类变量损失函数，‘liblinear’ 只能处理两分类（是或者否）. ‘newton-cg’, ‘lbfgs’ 和 ‘sag’ 只支持L2惩罚项。\n",
    "\n",
    "    三、Random Forest 随机森林\n",
    "\n",
    "        在Random Forest 模型中，常见可调参数有 ：\n",
    "        n_estimators : 随机森林中树的数量，也就是弱分类器的数量\n",
    "        criterion: 两种衡量分割效果的方法，有基尼系数法和熵法。\n",
    "        max_features : 寻找最佳分割时要考虑特征变量的个数\n",
    "        max_depth ：设置决策树最大深度，如果不设置该变量，决策树一直延伸直至每个叶节点都完美分类，或者所有叶节点内数量达到min_samples_split指定的样本数量。\n",
    "        min_samples_split: 分割一个内部节点所要求的最低样本含量，低于这个数量就不再分割了。\n",
    "        max_leaf_nodes :  叶节点最大数目，默认不限制叶节点的最大数量。\n",
    "        min_impurity_split: 如果纯度还高于阈值，继续分割，如果达到阈值，成为叶节点。\n",
    "        bootstrap : 在生长树的时候是否采用bootstrap的方法\n",
    "\n",
    "    四、最佳参数搜索\n",
    "        主要是两种原理，一种是Grid search（网格式搜索），把可调参数排列组合，比如模型有两个参数A和B，参数A有3个取值，参数B有2个取值，组合起来就是6种，用这6种取值去拟合数据后得到6个模型，利用交叉验证和评价指标来筛选最佳参数组合。第二种看函数名就可以猜到，是根据各参数的分布范围随机抽样后组合，同样利用交叉验证和评价指标来筛选最佳参数组合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络搜索调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'bootstrap': False, 'max_features': 4, 'n_estimators': 10},\n",
       " [mean: 0.90083, std: 0.02264, params: {'max_features': 2, 'n_estimators': 3},\n",
       "  mean: 0.92477, std: 0.03509, params: {'max_features': 2, 'n_estimators': 10},\n",
       "  mean: 0.93784, std: 0.00874, params: {'max_features': 2, 'n_estimators': 15},\n",
       "  mean: 0.92059, std: 0.02336, params: {'max_features': 4, 'n_estimators': 3},\n",
       "  mean: 0.92219, std: 0.02102, params: {'max_features': 4, 'n_estimators': 10},\n",
       "  mean: 0.93324, std: 0.01518, params: {'max_features': 4, 'n_estimators': 15},\n",
       "  mean: 0.91311, std: 0.02766, params: {'max_features': 6, 'n_estimators': 3},\n",
       "  mean: 0.93746, std: 0.01815, params: {'max_features': 6, 'n_estimators': 10},\n",
       "  mean: 0.94133, std: 0.02955, params: {'max_features': 6, 'n_estimators': 15},\n",
       "  mean: 0.93374, std: 0.01944, params: {'max_features': 8, 'n_estimators': 3},\n",
       "  mean: 0.93158, std: 0.03058, params: {'max_features': 8, 'n_estimators': 10},\n",
       "  mean: 0.93180, std: 0.03157, params: {'max_features': 8, 'n_estimators': 15},\n",
       "  mean: 0.92981, std: 0.02490, params: {'bootstrap': False, 'max_features': 2, 'n_estimators': 3},\n",
       "  mean: 0.93895, std: 0.01314, params: {'bootstrap': False, 'max_features': 2, 'n_estimators': 10},\n",
       "  mean: 0.90478, std: 0.01415, params: {'bootstrap': False, 'max_features': 3, 'n_estimators': 3},\n",
       "  mean: 0.94649, std: 0.01614, params: {'bootstrap': False, 'max_features': 3, 'n_estimators': 10},\n",
       "  mean: 0.93209, std: 0.03382, params: {'bootstrap': False, 'max_features': 4, 'n_estimators': 3},\n",
       "  mean: 0.94973, std: 0.01599, params: {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#建立一个随机森林分类器\n",
    "cfClf=RandomForestClassifier()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "##设置参数网格，随机森林默认的bootstrap是True，第一个网格只涉及两个参\n",
    "##数：树的数量和特征变量个数，前者有三个值可以选择，后者有四个值可\n",
    "##选，有12种组合，后面一个dict格式储存的是另一种网格，在bootstrap参数设\n",
    "##置为False的情况下，树的数量有两个值可选，max_feature有三个值可选，\n",
    "##共有6种组合，加上前面12种就是18种组合。\n",
    "hypermeter_grid=[{'n_estimators':[3,10,15],\n",
    "                'max_features':[2,4,6,8]},                 \n",
    "                 {'bootstrap':[False],\n",
    "                 'n_estimators':[3,10],\n",
    "                 'max_features':[2,3,4]}]           \n",
    "\n",
    "##设置三折交叉验证，评价指标选F1\n",
    "grid_search=GridSearchCV(cfClf,hypermeter_grid,cv=3,scoring='f1')\n",
    "\n",
    "#利用不同的参数组合去拟合数据 ，建立模型\n",
    "grid_search.fit(pred_features,diagnosis=='M')\n",
    "\n",
    "'''\n",
    "查看最佳的参数设置和各种组合得分情况\n",
    "得分最高的就是最佳参数选择\n",
    "\n",
    "\n",
    "'''\n",
    "grid_search.best_params_,grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机搜索调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.93376, std: 0.02735, params: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 9, 'min_samples_leaf': 1, 'min_samples_split': 5},\n",
       " mean: 0.91328, std: 0.02864, params: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 8, 'min_samples_leaf': 1, 'min_samples_split': 4},\n",
       " mean: 0.92819, std: 0.03303, params: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 2, 'min_samples_leaf': 10, 'min_samples_split': 8},\n",
       " mean: 0.90004, std: 0.03000, params: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 19, 'min_samples_leaf': 10, 'min_samples_split': 2},\n",
       " mean: 0.91638, std: 0.01274, params: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 12, 'min_samples_leaf': 6, 'min_samples_split': 9},\n",
       " mean: 0.93547, std: 0.01991, params: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 4, 'min_samples_split': 3},\n",
       " mean: 0.93012, std: 0.02864, params: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 6, 'min_samples_leaf': 6, 'min_samples_split': 9},\n",
       " mean: 0.92715, std: 0.03766, params: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 7, 'min_samples_leaf': 10, 'min_samples_split': 5},\n",
       " mean: 0.93232, std: 0.01652, params: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 4},\n",
       " mean: 0.91544, std: 0.02927, params: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 11, 'min_samples_leaf': 10, 'min_samples_split': 4}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "调用scipy里面的整数随机分布\n",
    "\n",
    "'''\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "'''\n",
    "将max_features,min_samples_split,以及min_samples_leaf的随机分布设置好，\n",
    "注意这里不能用np.random.randomint函数，这里要求的是分布不是抽样结果\n",
    "\n",
    "'''\n",
    "random_grid={\"max_depth\": [3, None], \n",
    "              \"max_features\": sp_randint(1, 20),  \n",
    "              \"min_samples_split\":sp_randint(2, 11), \n",
    "              \"min_samples_leaf\": sp_randint(1, 11),  \n",
    "              \"bootstrap\": [True, False], \n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "#随机抽取10次参数组合\n",
    "n_iteration=10\n",
    "\n",
    "#设置三次交叉验证，评价分数为F1\n",
    "random_grid_search=RandomizedSearchCV(cv=3,estimator=cfClf,n_iter=n_iteration,scoring='f1',param_distributions=random_grid)\n",
    "\n",
    "#拟合数据\n",
    "random_grid_search.fit(pred_features,diagnosis=='M')\n",
    "\n",
    "## 查看最佳F1得分\n",
    "random_grid_search.best_score_ \n",
    "## 查看最佳参数组合\n",
    "random_grid_search.best_params_\n",
    "## 查看10次参数组合的得分情况\n",
    "random_grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集成学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把分类算法集成起来，构建出一个效果更好的综合分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        机器学习称这种把机器学习模型集成起来的方法为ensemble learning（集成学习）。集成学习的原理很容易理解，非常intuitiv，就是把不同的机器学习模型组合起来，发挥各自的优势，扬长避短。集成学习有下面几个优势：\n",
    "\n",
    "        预测效果好，集成学习多数情况下优于单一模型的预测效果。在诸如kaggle这样的机器学习模型竞赛中，名列前茅的选手们往往无一例外使用ensemble learning的方法来提升模型的最终预测效果。\n",
    "\n",
    "        部分集成学习可以并列实现，在不同的cpu上跑不同的模型，然后将这些模型再集成起来\n",
    "\n",
    "        组合方法简单灵活，可以组合不同类型的机器学习模型，也可以组合同一类型的随机机器学习模型（典型案例就是决策树模型组合为随机森林），可以自己设定集成的规则。\n",
    "\n",
    "        集成各个学习器的结果主要是通过voting（投票）的方式。例如面对一个二分类问题（0和1）的时候，logistic回归给出一个分类结果1，svm预测的结果是0，朴素贝叶斯预测出来的是1，人工神经网络给出的是1，那么按照少数服从多数的原则，集成分类的预测结果就是1. 这在机器学习中称为hard voting 硬投票方式，还有soft voting 软投票方式，就是依据分类器给出的概率平均值结果来投票，比如A分类器预测的概率是{0：0.53，1:0.47}，B分类器预测出的概率是{0:0.36,1:0.64}，那分类为0的概率均值为（0.53+0.36）/2=0.445, 分类为1的概率为（0.47+0.64）/2=0.555，所以最终预测结果为分类1，当然soft voting仅限于那些能够给出分类概率的学习器。另外还可以给每个学习器设置不同权重，给效果较好的学习器赋予较大的权重，使其预测结果在最终决策中发挥作用更大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 集成学习的两种主要形式：bagging and boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        bagging就是反复有放回（或无放回）在样本数据集中随机抽出子样本作为训练集，不断从这些子样本训练出模型，然后把所有模型结果集成。bagging不仅 可以抽取数据样例（instance），也可以随机抽取特征（feature）。 总之可以理解为在样本空间里不断提取亚空间出来做训练集不断训练模型，最后把众多个模型集成起来。前面文章里用到的Random Forest随机森林就是bagging的典型代表。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        boosting也是把弱学习器集成为强学习器，和bagging的不同之处在于，大部分boosting方法强调有先后顺序的进行模型训练，从前一个学习器所犯的错误中学习，吃一堑长一智，不断迭代循环改进下一个学习器。然后再把所有的学习器按照一定的规则再集成其预测结果。boosting的两大主力分别为adaboosting和Gradient boosting。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        AdaBoosting的算法思想是给学习器和训练集的个案都赋予权重，表现越好的学习器权重越高，越难被预测准确的训练数据个案权重越高，越受重视。AdaBoosting的实现细节是：先给每个训练样本个案赋予权重（初始权重一般都是平等的），第一个学习器训练出来以后，会预测错一部分样本个案，根据预测错的比例以及个案权重来给该学习器本身计算一个权重，同时更新被分错训练集个案的权重（强调所犯错误），然后进行第二次训练，依照第二个学习器错误预测的情况和新个案权重再计算第二个学习器的权重，并再次更新个案的权重，如此依次迭代下去，直至学习器的数量达到预先指定的数量，或是迭代到一个非常完美的学习器。最后在做预测时，通过每个分类器的预测结果及分类器的权重对预测结果进行集成，得到最终的预测结果。\n",
    "\n",
    "        Gradient boosting同样也是关注上一个学习器所犯的错误，但是其方式不同于AdaBoosting。Gradient boosting是先训练一个学习器，然后计算这个学习器预测结果和实际值之间的残差e1，然后训练第二个学习器，第二个学习器的训练方法变了，不是去拟合原始数据y，而是去拟合e1，第二个学习器构建好以后，再次计算它的残差e2, 得到e2以后，就可以构建第三个学习器去拟合e2,将这个过程持续迭代，最后在预测时，把这些学习器的预测结果相加，就得到了最终预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "逻辑回归的混淆矩阵：\n",
      "[[71  1]\n",
      " [ 6 36]]\n",
      "支持向量机的混淆矩阵：\n",
      "[[70  2]\n",
      " [ 7 35]]\n",
      "随机森林的混淆矩阵：\n",
      "[[72  0]\n",
      " [ 3 39]]\n",
      "多层感知机的混淆矩阵：\n",
      "[[71  1]\n",
      " [12 30]]\n",
      "朴素贝叶斯的混淆矩阵：\n",
      "[[72  0]\n",
      " [ 7 35]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "##向量机，朴素贝叶斯，多层感知器，随机森林，\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "'''\n",
    "分割训练集和测试集数据，在测试集上计算每个分类学习算法的混淆矩阵\n",
    "\n",
    "'''\n",
    "\n",
    "cut=StratifiedShuffleSplit(n_splits=1,random_state=42,test_size=0.2)\n",
    "\n",
    "for a,b in cut.split(X=pred_features,y=diagnosis):\n",
    "    train_x,train_y=pred_features.iloc[a,:],diagnosis[a]\n",
    "    test_x,test_y=pred_features.iloc[b,:],diagnosis[b]\n",
    "    \n",
    "    \n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression  #逻辑回归分类器\n",
    "from sklearn.svm import SVC  #支持向量机分类器\n",
    "from sklearn.ensemble import RandomForestClassifier  #随机森林\n",
    "from sklearn.neural_network import MLPClassifier#多层感知机\n",
    "from sklearn.naive_bayes import GaussianNB#朴素贝叶斯\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "逻辑回归\n",
    "\n",
    "'''\n",
    "logClf=LogisticRegression()\n",
    "test_pred_log=logClf.fit(train_x,train_y).predict(test_x)\n",
    "print(\"逻辑回归的混淆矩阵：\")\n",
    "print(confusion_matrix(test_y,test_pred_log))\n",
    "\n",
    "'''\n",
    "\n",
    "支持向量机\n",
    "\n",
    "'''\n",
    "svmClf=SVC(kernel='linear',C=1,random_state=42)\n",
    "test_pred_svm=svmClf.fit(train_x,train_y).predict(test_x)\n",
    "print(\"支持向量机的混淆矩阵：\")\n",
    "print(confusion_matrix(test_y,test_pred_svm))\n",
    "\n",
    "\n",
    "'''\n",
    "随机森林\n",
    "\n",
    "'''\n",
    "rfClf=RandomForestClassifier()\n",
    "test_pred_rf=rfClf.fit(train_x,train_y).predict(test_x)\n",
    "print(\"随机森林的混淆矩阵：\")\n",
    "print(confusion_matrix(test_y,test_pred_rf))\n",
    "\n",
    "'''\n",
    "多层感知机\n",
    "\n",
    "'''\n",
    "MLPclf=MLPClassifier(activation=\"relu\",batch_size=80,hidden_layer_sizes=(30,20,20,15),max_iter=4000,random_state=42,learning_rate_init=0.001)\n",
    "test__pred_MLP=MLPclf.fit(train_x,train_y).predict(test_x)\n",
    "print(\"多层感知机的混淆矩阵：\")\n",
    "print(confusion_matrix(test_y,test__pred_MLP))\n",
    "\n",
    "'''\n",
    "\n",
    "朴素贝叶斯\n",
    "\n",
    "'''\n",
    "nbClf=GaussianNB()\n",
    "test_pred_nb=nbClf.fit(train_x,train_y).predict(test_x)\n",
    "print(\"朴素贝叶斯的混淆矩阵：\")\n",
    "print(confusion_matrix(test_y,test_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集成学习的混淆矩阵是：\n",
      "[[72  0]\n",
      " [ 5 37]]\n",
      "0.936708860759\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "集成学习\n",
    "\n",
    "'''\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "vot=VotingClassifier(estimators=[('logistic',logClf),(\"svm\",svmClf),(\"rf\",rfClf),(\"nb\",nbClf),(\"nn\",MLPclf)],voting=\"hard\")\n",
    "votClf=vot.fit(train_x,train_y)\n",
    "vot_pred=votClf.predict(test_x)\n",
    "print(\"集成学习的混淆矩阵是：\")\n",
    "print(confusion_matrix(test_y,vot_pred))\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(test_y==\"M\",vot_pred==\"M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
