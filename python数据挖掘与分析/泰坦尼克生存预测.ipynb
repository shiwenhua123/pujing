{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样例说明：题目来自于机器学习竞赛网站kaggle：\n",
    "https://www.kaggle.com/c/titanic/data\n",
    "一、数据收集\n",
    "数据收集无需要多讲，直接从这里下载：\n",
    "https://www.kaggle.com/c/titanic/data\n",
    "数据集的初步了解，kaggle中对数据集有明确的说明，为方便大家，在此作个简要的中文说明。想要学习机器学习的朋友，最好还是尝试阅读英文的资料。\n",
    "此数据集是描述在泰坦尼克号中乘客的信息以及乘客最终是否幸存下来。\n",
    "\n",
    "\n",
    "变量及含义：\n",
    "survival，是否幸存，0为否，1为是\n",
    "pclass\n",
    " ，票的等级，1代表一等仓，2代表二等仓，3代表三等仓\n",
    "sex\n",
    " ， 性别，male：男性，female：女性\n",
    "Age，年龄\n",
    "sibsp，兄弟姐妹或配偶同行的数量\n",
    "parch，父母或子女同行的数量\n",
    "ticket，票号\n",
    "fare，票价\n",
    "cabin，客仓号\n",
    "embarked，登船口\n",
    "数据，请到如下链接下载或者到kaggle下载。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "数据预处理使用pandas，数据预处理代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import pandas as pd   #导入pandas数据分析库，用于数据预处理\n",
    "import numpy as np\n",
    "train=pd.read_csv('F:\\\\sklearn\\\\train.csv')\n",
    "def yuchuli():\n",
    "    #train.head(5)                 #查看前5行数据\n",
    "    #train.describe()              #输出相关统计量\n",
    "    train['Age']=train['Age'].fillna(train['Age'].median())  #用均值填充 缺失值\n",
    "    #train.describe()               #输出相关统计量\n",
    "    #train['Sex'].unique()          #查看弄个特征有多少个不同的取值#array(['male','femaldtype=object)\n",
    "    train.loc[train['Sex']==\"male\",'Sex']=0     #将Sex特征向量的male取值设置为0\n",
    "    train.loc[train['Sex']==\"female\",'Sex']=1    #将Sex特征向量的female取值设置为1\n",
    "    #train.head()\n",
    "    #train['Embarked'].unique()     #array(['S', 'C', 'Q', nan]\n",
    "    #train[train['Embarked']=='S'].count()  #644个，比例特别巨大\n",
    "    #train[train['Embarked'].isnull()]  #2个空值\n",
    "    train['Embarked']=train['Embarked'].fillna('S')  #用众数补全空值\n",
    "    #train['Embarked'].describe()\n",
    "    train.loc[train['Embarked']=='S','Embarked']=0\n",
    "    train.loc[train['Embarked']=='C','Embarked']=1\n",
    "    train.loc[train['Embarked']=='Q','Embarked']=2\n",
    "    #train.head(6)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型1：线性回归\n",
    "    线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w'x+e，e为误差服从均值为0的正态分布。\n",
    "    回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。\n",
    "\n",
    "线性回归模型，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.261503928171\n"
     ]
    }
   ],
   "source": [
    "#线性回归\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#交叉验证:将训练数据集分成3份，对这三份进行交叉验证，比如使用1，2样本测试，3号样本验证\n",
    "#对最后得到得数据取平均值\n",
    "from sklearn.cross_validation import KFold\n",
    "def xianxing_huigui():\n",
    "    predictors=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']  #选取一些特征\n",
    "    LR=LinearRegression()    #创建线性回归模型\n",
    "    kf=KFold(train.shape[0],n_folds=3,random_state=1)   #交叉验证，等分出3等分，两两交叉验证\n",
    "    predictions=[]  #用于保存预测标签结果集\n",
    "    for train1,test in kf: #进行交叉验证\n",
    "        train_predictors=(train[predictors].iloc[train1,:])    #拿到特征向量\n",
    "        train_target=train['Survived'].iloc[train1]           #拿到标签\n",
    "        LR.fit(train_predictors,train_target)           #拟合模型\n",
    "        test_predictions=LR.predict(train[predictors].iloc[test,:])   #拿预测数据去预测得到预测标签\n",
    "        predictions.append(test_predictions)\n",
    "    #线性回归\n",
    "    predictions=np.concatenate(predictions,axis=0)\n",
    "    #将0到1之间的区间值，变成具体的是否被获救，1代表被获救\n",
    "    predictions[predictions>0.5]=1\n",
    "    predictions[predictions<=0.5]=0\n",
    "    accuracy=sum(predictions[predictions==train['Survived']])/len(predictions)   #获得准确率\n",
    "    return accuracy   #返回准确率\n",
    "\n",
    "train=yuchuli()\n",
    "acc=xianxing_huigui()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型2：\n",
    "逻辑回归：http://blog.csdn.net/pakko/article/details/37878837\n",
    "逻辑回归模型，代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787878787879\n"
     ]
    }
   ],
   "source": [
    "#使用逻辑回归算法，它虽然是回归算法，但是一般都用来分类\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def  Logistic():\n",
    "    alg=LogisticRegression(random_state=1)\n",
    "    predictors=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']  #选取一些特征\n",
    "    scores=cross_validation.cross_val_score(alg,train[predictors],train['Survived'],cv=3)\n",
    "    #注意，逻辑回归和线性回归得到的结果类型不一样，逻辑回归是概率值，线性回归是[0,1]区间的数值\n",
    "    return scores.mean() #返回准确率\n",
    "\n",
    "acc=Logistic()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型3：\n",
    "随机森林：在机器学习中，随机森林是一个包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。\n",
    "随机森林参数介绍\n",
    "1、随机森林框架参数：\n",
    "　1) n_estimators: 也就是弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说n_estimators太小，容易欠拟合，n_estimators太大，计算量会太大，并且n_estimators到一定的数量后，再增大n_estimators获得的模型提升会很小，所以一般选择一个适中的数值。默认是100。在实际调参的过程中，我们常常将n_estimators和learning_rate一起考虑。\n",
    "\n",
    "　2) oob_score :即是否采用袋外样本来评估模型的好坏。默认识False。个人推荐设置为True，因为袋外分数反应了一个模型拟合后的泛化能力。\n",
    "\n",
    "　3) criterion: 即CART树做划分时对特征的评价标准。分类模型和回归模型的损失函数是不一样的。分类RF对应的CART分类树默认是基尼系数gini,另一个可选择的标准是信息增益。回归RF对应的CART回归树默认是均方差mse，另一个可以选择的标准是绝对值差mae。一般来说选择默认的标准就已经很好的。\n",
    "2、随机森林决策树参数\n",
    "1) RF划分时考虑的最大特征数max_features: 可以使用很多种类型的值，默认是\"None\",意味着划分时考虑所有的特征数；\n",
    "2) 决策树最大深度max_depth\n",
    "3) 内部节点再划分所需最小样本数min_samples_split\n",
    "4) 叶子节点最少样本数min_samples_leaf\n",
    "5）叶子节点最小的样本权重和min_weight_fraction_leaf\n",
    "6) 最大叶子节点数max_leaf_nodes\n",
    "7) 节点划分最小不纯度min_impurity_split:\n",
    "上面决策树参数中最重要的包括最大特征数max_features， 最大深度max_depth， 内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机深林模型，代码如下：\n",
    "#随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.862071317488\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.8429\n",
      "AUC Score (Train): 0.900010\n",
      "CV Score : Mean - 0.8620713 | Std - 0.02956678 | Min - 0.8151836 | Max - 0.9049689\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAExCAYAAABcTDVcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5cd340be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1.样本是随机的，有放回的取样  2.特征的选择也是随机的，防止过拟合  3.多颗决策树，取平均值\n",
    "from sklearn import cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV      #用于进行梯度下降调参\n",
    "#选中一些特征\n",
    "predictors = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]\n",
    "#random_state=1表示此处代码多运行几次得到的随机值都是一样的，如果不设置，两次执行的随机值是不一样的\n",
    "#n_estimators指定有多少颗决策树，树的分裂的条件是:min_samples_split代表样本不停的分裂，某一个节点上的样本如果只有2个了\n",
    "#就不再继续分裂了，min_samples_leaf是控制叶子节点的最小个数\n",
    "\n",
    "\n",
    "#进行梯度下降调参，首先调n_estimators(树的个数)结果为{'n_estimators': 26},0.8575893301684556)\n",
    "\n",
    "#param_test={'n_estimators':list(range(10,100,2))}\n",
    "#gsearch=GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,\\\n",
    "#                    min_samples_leaf=20,max_depth=8,max_features='sqrt' ,random_state=10),\\\n",
    "#                     param_grid = param_test, scoring='roc_auc',cv=5)\n",
    "#gsearch.fit(train[predictors],train[\"Survived\"])\n",
    "#gsearch.grid_scores_, gsearch.best_params_, gsearch.best_score_\n",
    "\n",
    "\n",
    "#进行梯度下降的调参,调max_depth,结果是5     # 0.8600357350447354\n",
    "#param_test={'max_depth':list(range(3,14,1))}\n",
    "#gsearch=GridSearchCV(estimator = RandomForestClassifier(n_estimators=26,\\\n",
    "#                    min_samples_split=100,min_samples_leaf=20,max_features='sqrt' ,random_state=10),\\\n",
    "#                     param_grid = param_test, scoring='roc_auc',cv=5)\n",
    "#gsearch.fit(train[predictors],train[\"Survived\"])\n",
    "#gsearch.grid_scores_, gsearch.best_params_, gsearch.best_score_\n",
    "\n",
    "#进行梯度下降的调参,调min_samples_split,结果{'min_samples_split': 15}, 0.8551051934258219\n",
    "#param_test={'min_samples_split':list(range(15,50,2))}\n",
    "#gsearch=GridSearchCV(estimator = RandomForestClassifier(n_estimators=26,\\\n",
    "#                    max_depth=5,min_samples_leaf=20,max_features='sqrt' ,random_state=10),\\\n",
    "#                     param_grid = param_test, scoring='roc_auc',cv=5)\n",
    "#gsearch.fit(train[predictors],train[\"Survived\"])\n",
    "#gsearch.grid_scores_, gsearch.best_params_, gsearch.best_score_\n",
    "\n",
    " \n",
    "#进行梯度下降的调参,调min_samples_leaf {'min_samples_leaf': 4},0.8696662429496531\n",
    "#param_test={'min_samples_leaf':list(range(1,15,1))}\n",
    "#gsearch=GridSearchCV(estimator = RandomForestClassifier(n_estimators=26,\\\n",
    "#                    max_depth=5,min_samples_split=15,max_features='sqrt' ,random_state=10),\\\n",
    "#                     param_grid = param_test, scoring='roc_auc',cv=5)\n",
    "#gsearch.fit(train[predictors],train[\"Survived\"])\n",
    "#gsearch.grid_scores_, gsearch.best_params_, gsearch.best_score_\n",
    "alg = RandomForestClassifier(random_state=1,n_estimators=26,max_depth=5,min_samples_split=15,min_samples_leaf=4)#进行交叉验证\n",
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Survived'])\n",
    "\n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "\n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        kf = cross_validation.KFold(train.shape[0],n_folds=cv_folds,random_state=1)\n",
    "        cv_score = cross_validation.cross_val_score(alg, dtrain[predictors], dtrain['Survived'], cv=kf, scoring='roc_auc')\n",
    "\n",
    "    #Print model report:\n",
    "    print(\"准确率：\",cv_score.mean())\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Survived'].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Survived'], dtrain_predprob))\n",
    "\n",
    "    if performCV:\n",
    "        print(\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "    \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')\n",
    "        \n",
    "modelfit(alg, train, predictors)\n",
    "\n",
    "#def RandomForest():\n",
    "#    alg = RandomForestClassifier(random_state=1,n_estimators=26,max_depth=5,min_samples_split=15,min_samples_leaf=4)#进行交叉验证\n",
    "#    kf = cross_validation.KFold(train.shape[0],n_folds=3,random_state=1)\n",
    "#    scores = cross_validation.cross_val_score(alg,train[predictors],train[\"Survived\"],cv=kf)\n",
    "#    print (scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型4：\n",
    "梯度提升具体可参考http://www.jianshu.com/p/005a4e6ac775\n",
    "梯度提升模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.860990099791\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.9416\n",
      "AUC Score (Train): 0.989585\n",
      "CV Score : Mean - 0.8609901 | Std - 0.02926617 | Min - 0.8245056 | Max - 0.8977226\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAExCAYAAABcTDVcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWpIkSRqBBbUkSZI0gv8PKSO4PhyztIcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5cd34097f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#梯度提升模型\n",
    "from sklearn import cross_validation\n",
    "#from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "#进行梯度下降的调参,首先调n_estimators,结果是88 #.086\n",
    "#para_test = {'n_estimators':list(range(20,100,2))}\n",
    "#gsearch = GridSearchCV(estimator=GradientBoostingClassifier(learning_rate=0.1,min_samples_split=300,min_samples_leaf=20,max_features='sqrt',subsample=0.8,random_state=10),param_grid=para_test,scoring='roc_auc',iid=False,cv=5)\n",
    "#gsearch.fit(train[predictors],train[\"Survived\"])\n",
    "#gsearch.best_params_,gsearch.best_score_\n",
    "\n",
    "#进行梯度下降的调参,调max_depth,结果是11     #0.87496181636160275\n",
    "#para_test = {'max_depth':list(range(5,12,1))}\n",
    "#gsearch = GridSearchCV(estimator=GradientBoostingClassifier(learning_rate=0.1,n_estimators=88,min_samples_leaf=20,max_features='sqrt',subsample=0.8,random_state=10),param_grid=para_test,scoring='roc_auc',iid=False,cv=5)\n",
    "#gsearch.fit(train[predictors],train[\"Survived\"])\n",
    "#gsearch.best_params_,gsearch.best_score_\n",
    "\n",
    "    \n",
    "#进行梯度下降的调参,调min_samples_split,结果是20  #0.87\n",
    "#para_test = {'min_samples_split':list(range(20,35,1))}\n",
    "#gsearch = GridSearchCV(estimator=GradientBoostingClassifier(learning_rate=0.1,n_estimators=88,min_samples_leaf=20,max_depth=11,max_features='sqrt',subsample=0.8,random_state=10),param_grid=para_test,scoring='roc_auc',iid=False,cv=5)\n",
    "#gsearch.fit(train[predictors],train[\"Survived\"])\n",
    "#gsearch.best_params_,gsearch.best_score_\n",
    "\n",
    "#进行梯度下降的调参,调min_samples_leaf,结果是14  #0.87\n",
    "#para_test = {'min_samples_leaf':list(range(1,15,1))}\n",
    "#gsearch = GridSearchCV(estimator=GradientBoostingClassifier(learning_rate=0.1,n_estimators=88,min_samples_split=20,max_depth=11,max_features='sqrt',subsample=0.8,random_state=10),param_grid=para_test,scoring='roc_auc',iid=False,cv=5)\n",
    "#gsearch.fit(train[predictors],train[\"Survived\"])\n",
    "#gsearch.best_params_,gsearch.best_score_\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=1,n_estimators=86,max_depth=11,min_samples_split=20,min_samples_leaf=14)\n",
    "#clf.fit(train[predictors],train[\"Survived\"])\n",
    "#kf = cross_validation.KFold(train.shape[0],n_folds=3,random_state=1)\n",
    "#scores = cross_validation.cross_val_score(clf,train[predictors],train[\"Survived\"],cv=kf)\n",
    "#print(scores.mean())\n",
    "\n",
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Survived'])\n",
    "\n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "\n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        kf = cross_validation.KFold(train.shape[0],n_folds=cv_folds,random_state=1)\n",
    "        cv_score = cross_validation.cross_val_score(alg, dtrain[predictors], dtrain['Survived'], cv=kf, scoring='roc_auc')\n",
    "\n",
    "    #Print model report:\n",
    "    print(cv_score.mean())\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Survived'].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Survived'], dtrain_predprob))\n",
    "\n",
    "    if performCV:\n",
    "        print(\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "    \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')\n",
    "\n",
    "\n",
    "modelfit(clf, train, predictors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "========================\n",
      "========================\n",
      "========================\n",
      "========================\n",
      "准确率： 0.880239520958\n",
      "========================\n",
      "========================\n",
      "========================\n",
      "========================\n",
      "========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_file='F:\\\\sklearn\\\\train.csv'\n",
    "train=pd.read_csv(train_file)\n",
    "train.columns\n",
    "train.describe()\n",
    "train['Age']=train['Age'].fillna(train['Age'].median())#用均值来填充缺失的Age\n",
    "train.describe()\n",
    "train['Sex'].unique()\n",
    "train.loc[train['Sex']=='male','Sex']=0\n",
    "train.loc[train['Sex']=='female','Sex']=1\n",
    "train['Embarked'].unique()\n",
    "train['Embarked']=train['Embarked'].fillna('S')\n",
    "train.loc[train['Embarked']=='S','Embarked']=0\n",
    "train.loc[train['Embarked']=='C','Embarked']=1\n",
    "train.loc[train['Embarked']=='Q','Embarked']=2\n",
    "predictors=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\n",
    "X=train[predictors]   \n",
    "y=train[['Survived']]\n",
    "from sklearn.cross_validation import train_test_split#划分训练集和测试集\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=1)\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#数据标准化\n",
    "ss=StandardScaler()\n",
    "for c in predictors:\n",
    "    X_train[c]=ss.fit_transform(X_train[c])\n",
    "    X_test[c]=ss.transform(X_test[c])\n",
    "xgb=XGBClassifier()\n",
    "xgb.fit(X_train,y_train)\n",
    "score=xgb.score(X_train,y_train)\n",
    "print(\"========================\")\n",
    "print(\"========================\")\n",
    "print(\"========================\")\n",
    "print(\"========================\")\n",
    "print(\"========================\")\n",
    "\n",
    "print(\"准确率：\",score)\n",
    "\n",
    "print(\"========================\")\n",
    "print(\"========================\")\n",
    "print(\"========================\")\n",
    "print(\"========================\")\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
