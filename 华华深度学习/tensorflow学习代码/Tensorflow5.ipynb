{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /path/to/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets(\"/path/to/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[0]\n",
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "xs,ys=mnist.train.next_batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /path/to/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-7-71963c597890>:80: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "After 0 training  step(S),validation accuracy using average model is 0.0854 \n",
      "After 1000 training  step(S),validation accuracy using average model is 0.9784 \n",
      "After 2000 training  step(S),validation accuracy using average model is 0.9816 \n",
      "After 3000 training  step(S),validation accuracy using average model is 0.9832 \n",
      "After 4000 training  step(S),validation accuracy using average model is 0.9834 \n",
      "After 4999 training  step(S),test accuracy using average model is 0.982 \n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#输入层和输出层的节点数\n",
    "INPUT_NODE=784\n",
    "OUTPUT_NODE=10\n",
    "\n",
    "#配置神经网络的参数\n",
    "LAYER1_NNODE=500\n",
    "\n",
    "BATCH_SIZE=100\n",
    "LEARNING_RATE_BASE=0.8   #基础的学习率\n",
    "LEARNING_RATE_DECAY=0.99   #学习率的衰减率\n",
    "REGULARIZATION_RATE=0.0001    #描述模型复杂度的正则化项在损失函数中的系数\n",
    "TRAINING_STEPS=5000          #循环轮次\n",
    "MOVING_AVERAGE_DECAY=0.99        #滑动平均衰减率\n",
    "\n",
    "def inference(input_tensor,avg_class,w1,b1,w2,b2):\n",
    "    #当没有提供滑动平滑类时，直接使用参数挡墙的取值\n",
    "    if(avg_class==None):\n",
    "        layer1=tf.nn.relu(tf.matmul(input_tensor,w1)+b1)\n",
    "        return tf.matmul(layer1,w2)+b2\n",
    "    else:\n",
    "        #首先使用avg_class.average函数来计算得出变量的滑动平均值。\n",
    "        #然后再计算相应的神经网络的前向传播结果。\n",
    "        layer1=tf.nn.relu(tf.matmul(input_tensor,avg_class.average(w1))+avg_class.average(b1))\n",
    "        return tf.matmul(layer1,avg_class.average(w2))+avg_class.average(b2)\n",
    "\n",
    "#训练模型的过程\n",
    "def train(mnist):\n",
    "    x=tf.placeholder(tf.float32,shape=(None,INPUT_NODE),name=\"X_input\")\n",
    "    y_=tf.placeholder(tf.float32,shape=(None,OUTPUT_NODE),name=\"Y_input\")\n",
    "    \n",
    "    #生成隐藏层参数\n",
    "    w1=tf.Variable(tf.random_normal([INPUT_NODE,LAYER1_NNODE],stddev=0.1))\n",
    "    b1=tf.Variable(tf.constant(0.1,shape=[LAYER1_NNODE]))\n",
    "    \n",
    "    w2=tf.Variable(tf.random_normal([LAYER1_NNODE,OUTPUT_NODE],stddev=0.1))\n",
    "    b2=tf.Variable(tf.constant(0.1,shape=[OUTPUT_NODE]))\n",
    "    #计算当前参数下的神经网络的前向传播结果，这里给出用于计算滑动平均的类为None\n",
    "    #所以函数不会使用参数的滑动平均值\n",
    "    y=inference(x,None,w1,b1,w2,b2)\n",
    "    #定义存储训练轮次的变量，改变量为不可训练变量。\n",
    "    global_step=tf.Variable(0,trainable=False)\n",
    "    \n",
    "    #给定滑动平均衰减率和训练轮数变量，初始化滑动平均类,给定训练轮次的变量可以加快训练早期变量的更新速度\n",
    "    variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)\n",
    "    #在所有代表神经网络的参数上使用滑动平均，其他辅助变量就不用了\n",
    "    variable_averages_op=variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    #计算使用了滑动平均之后的前向传播结果\n",
    "    average_y=inference(x,variable_averages,w1,b1,w2,b2)\n",
    "    \n",
    "    #计算交叉熵用于刻画预测值和真实值之间差距的损失函数。\n",
    "    cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,1))\n",
    "    #计算当前batch中所有样例交叉熵的平均值\n",
    "    cross_entropy_mean=tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    #计算L2正则化损失函数\n",
    "    regularizer=tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    #计算模型的正则化损失，一般只计算神经网络边上权重的正则化损失，而不使用偏置项。\n",
    "    regularization=regularizer(w1)+regularizer(w2)\n",
    "    #总损失等于交叉熵损失加上正则化损失\n",
    "    loss=cross_entropy_mean+regularization\n",
    "    #设置指数衰减学习率\n",
    "    learning_rate=tf.train.exponential_decay(LEARNING_RATE_BASE,global_step,mnist.train.num_examples/BATCH_SIZE,LEARNING_RATE_DECAY)\n",
    "    #这里使用梯度下降算法来优化损失函数\n",
    "    train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "\n",
    "    #在训练神经网络模型时候，过一变数据既要通过反向传播来更新神经网络中的参数，又要更新每一个参数的滑动平均值\n",
    "    with tf.control_dependencies([train_step,variable_averages_op]):\n",
    "        train_op=tf.no_op(name='train')\n",
    "    #检验使用了滑动平均模型的神经网络前向传播结果是否正确\n",
    "    correct_prediction=tf.equal(tf.argmax(average_y,1),tf.argmax(y_,1))\n",
    "    #正确率\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "    #初始化会话并开始训练过程\n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        #准备验证数据\n",
    "        validate_feed={x:mnist.validation.images,y_:mnist.validation.labels}\n",
    "        #准备测试数据\n",
    "        test_feed={x:mnist.test.images,y_:mnist.test.labels}\n",
    "        #迭代的训练神经网络\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            #没1千轮输出一次在验证集上的测试结果\n",
    "            if(i%1000==0):\n",
    "                validate_acc=sess.run(accuracy,feed_dict=validate_feed)\n",
    "                print(\"After %d training  step(S),validation accuracy using average model is %g \" % (i,validate_acc))\n",
    "            #产生这一轮使用的一个batch的训练数据，并运行训练过程\n",
    "            xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op,feed_dict={x:xs,y_:ys})\n",
    "        #在训练结束之后，在测试数据上检验模型的最终准确率\n",
    "        test_acc=sess.run(accuracy,feed_dict=test_feed)\n",
    "        print(\"After %d training  step(S),test accuracy using average model is %g \" % (i,test_acc))\n",
    "\n",
    "def main(argv=None):\n",
    "    mnist=input_data.read_data_sets(\"/path/to/MNIST_data/\",one_hot=True)\n",
    "    train(mnist)\n",
    "if __name__=='__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\"):\n",
    "    v=tf.get_variable(\"v\",shape=[1],initializer=tf.constant_initializer(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\",reuse=True):\n",
    "    v=tf.get_variable(\"v\",shape=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-a5b2a3e273fe>:8: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "v1=tf.Variable(tf.constant(1.0,shape=[1]),name=\"v1\")\n",
    "v2=tf.Variable(tf.constant(2.0,shape=[1]),name=\"v2\")\n",
    "result=v1+v2\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    saver.save(sess,\"/path/Tensorflow/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /path/Tensorflow/model.ckpt.meta\n"
     ]
    },
    {
     "ename": "DataLossError",
     "evalue": "Unable to open table file \\path\\Tensorflow\\model.ckpt.meta: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save_9/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_9/Const_0, save_9/RestoreV2/tensor_names, save_9/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_9/RestoreV2', defined at:\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-942f3e7fbf1b>\", line 7, in <module>\n    saver=tf.train.Saver()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nDataLossError (see above for traceback): Unable to open table file \\path\\Tensorflow\\model.ckpt.meta: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save_9/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_9/Const_0, save_9/RestoreV2/tensor_names, save_9/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: Unable to open table file \\path\\Tensorflow\\model.ckpt.meta: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save_9/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_9/Const_0, save_9/RestoreV2/tensor_names, save_9/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-942f3e7fbf1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[1;31m#tf.initialize_all_variables().run()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"/path/Tensorflow/model.ckpt.meta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1457\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: Unable to open table file \\path\\Tensorflow\\model.ckpt.meta: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save_9/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_9/Const_0, save_9/RestoreV2/tensor_names, save_9/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_9/RestoreV2', defined at:\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-942f3e7fbf1b>\", line 7, in <module>\n    saver=tf.train.Saver()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nDataLossError (see above for traceback): Unable to open table file \\path\\Tensorflow\\model.ckpt.meta: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save_9/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_9/Const_0, save_9/RestoreV2/tensor_names, save_9/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "#加载模型\n",
    "import tensorflow as tf\n",
    "v1=tf.Variable(tf.constant(1.0,shape=[1]),name=\"v1\")\n",
    "v2=tf.Variable(tf.constant(2.0,shape=[1]),name=\"v2\")\n",
    "result=v1+v2\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    #tf.initialize_all_variables().run()\n",
    "    saver.restore(sess,\"/path/Tensorflow/model.ckpt.meta\")\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-43aaa36c0344>:7: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "v1=tf.Variable(tf.constant(1.0,shape=[1]),name=\"v1\")\n",
    "v2=tf.Variable(tf.constant(2.0,shape=[1]),name=\"v2\")\n",
    "result=v1+v2\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    #导出当前计算图的GraphDef部分，只需要这一部分就可以完成输入到输出的计算过程。\n",
    "    graph_def=tf.get_default_graph().as_graph_def()\n",
    "    output_graph_def=graph_util.convert_variables_to_constants(sess,graph_def,['add'])\n",
    "    \n",
    "    #将导出的模型写入文件。\n",
    "    with tf.gfile.GFile(\"/path/to/model/combined_model.pb\",\"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 3.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "with tf.Session() as sess:\n",
    "    model_file=\"/path/to/model/combined_model.pb\"\n",
    "    #读取保存的模型文件\n",
    "    with gfile.FastGFile(model_file,'rb') as f:\n",
    "        graph_def=tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    result=tf.import_graph_def(graph_def,return_elements=[\"add:0\"])\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#定义神经网络的相关参数\n",
    "INPUT_NODE=784\n",
    "OUTPUT_NODE=10\n",
    "LAYER1_NODE=500\n",
    "\n",
    "def get_weigth_variable(shape,regularizer):\n",
    "    #weigths=tf.Variable()\n",
    "    weigths = tf.get_variable(\"weights\", shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    #当给出了正则化生成函数时，将当前变量的正则化损失加入名字为losses的集合中去，\n",
    "    if(regularizer!=None):\n",
    "        tf.add_to_collection('losses',regularizer(weigths))\n",
    "    return weigths\n",
    "\n",
    "#定义神经网络的前向传播过程\n",
    "def inference(input_tensor,regularizer):\n",
    "    #声明第一层神经网络的变量并完成前向传播过程\n",
    "    with tf.variable_scope('layer1',reuse=None):\n",
    "        weigths=get_weigth_variable([INPUT_NODE,LAYER1_NODE],regularizer)\n",
    "        biases=tf.get_variable(\"biases\",[LAYER1_NODE],initializer=tf.constant_initializer(0.0))\n",
    "        layer1=tf.nn.relu(tf.matmul(input_tensor,weigths)+biases)\n",
    "    #声明第二层神经网络的变量并完成前向传播过程\n",
    "    with tf.variable_scope('layer2',reuse=None):\n",
    "        weigths=get_weigth_variable([LAYER1_NODE,OUTPUT_NODE],regularizer)\n",
    "        biases=tf.get_variable(\"biases\",[OUTPUT_NODE],initializer=tf.constant_initializer(0.0))\n",
    "        layer2=tf.matmul(layer1,weigths)+biases\n",
    "    return layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /path/to/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-2-994a735417a5>:49: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "After 1 training step(s),loss on training batch is 3.19616.\n",
      "After 1001 training step(s),loss on training batch is 0.278093.\n",
      "After 2001 training step(s),loss on training batch is 0.152246.\n",
      "After 3001 training step(s),loss on training batch is 0.128788.\n",
      "After 4001 training step(s),loss on training batch is 0.114241.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#配置神经网络参数\n",
    "BATCH_SIZE=100\n",
    "LEARNING_RATE_BASE=0.8   #基础学习率\n",
    "LEARNING_RATE_DECAY=0.99     #学习率的衰减率\n",
    "REGULARAZTION_RATE=0.0001  #描述模型复杂度的正则化项在损失函数中的系数\n",
    "TRAINING_STEPS=5000       #训练次数\n",
    "MOVING_AVERAGE_DECAY=0.99     #滑动平均衰减率\n",
    "\n",
    "#模型保存的路径和文件名\n",
    "MODEL_SAVE_PATH=\"/path/to/model/\"\n",
    "MODEL_NAME=\"model.ckpt\"\n",
    "\n",
    "\n",
    "def train(mnist):\n",
    "    x=tf.placeholder(tf.float32,[None,INPUT_NODE],name=\"x\")\n",
    "    y_=tf.placeholder(tf.float32,[None,OUTPUT_NODE],name=\"y\")\n",
    "    \n",
    "    #L2正则化损失函数\n",
    "    regularizer=tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n",
    "    #直接使用前向传播算法\n",
    "    y=inference(x,regularizer)\n",
    "    #定义训练轮次的变量\n",
    "    global_step=tf.Variable(0,trainable=False)\n",
    "    \n",
    "    #接下来定义损失函数，学习率，滑动平均值，以及训练过程\n",
    "    variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)\n",
    "    variable_averages_op=variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    #交叉熵\n",
    "    cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,1))\n",
    "    cross_entropy_mean=tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    #总损失\n",
    "    loss=cross_entropy_mean+tf.add_n(tf.get_collection('losses'))\n",
    "    \n",
    "    #设置学习率和优化损失函数\n",
    "    learning_rate=tf.train.exponential_decay(LEARNING_RATE_BASE,global_step,mnist.train.num_examples/BATCH_SIZE,LEARNING_RATE_DECAY)\n",
    "    train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step)\n",
    "    with tf.control_dependencies([train_step,variable_averages_op]):\n",
    "        train_op=tf.no_op(name='train')\n",
    "        \n",
    "    #初始化持久化类\n",
    "    saver=tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "            _,loss_value,step=sess.run([train_op,loss,global_step],feed_dict={x:xs,y_:ys})\n",
    "            \n",
    "            #每1000轮保存一次模型\n",
    "            if(i%1000==0):\n",
    "                print(\"After %d training step(s),loss on training batch is %g.\" %(step,loss_value))\n",
    "                saver.save(sess,os.path.join(MODEL_SAVE_PATH,MODEL_NAME),global_step=global_step)\n",
    "\n",
    "def main(argv=None):\n",
    "    mnist=input_data.read_data_sets(\"/path/to/MNIST_data/\",one_hot=True)\n",
    "    train(mnist)\n",
    "if __name__=='__main__':\n",
    "    tf.app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /path/to/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n",
      "INFO:tensorflow:Restoring parameters from /path/to/model/model.ckpt-4001\n",
      "After 4001 training step(s),validation accuracy=0.9832 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-45f167076ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-45f167076ea2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmnist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/path/to/MNIST_data/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-45f167076ea2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(mnist)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No ckickpoint file found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEVAL_INTERVAL_SECS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmnist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/path/to/MNIST_data/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#每10秒加载一次新的模型\n",
    "import time\n",
    "EVAL_INTERVAL_SECS=10\n",
    "def evaluate(mnist):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        #定义输入输出的格式\n",
    "        x=tf.placeholder(tf.float32,[None,INPUT_NODE],name='X')\n",
    "        y_=tf.placeholder(tf.float32,[None,OUTPUT_NODE],name='Y')\n",
    "        validate_feed={x:mnist.validation.images,y_:mnist.validation.labels}\n",
    "        #直接调用封装好的函数计算前向传播结果，因为测试的时候不需要关系正则化损失的值，所以这里用于计算正则化损失的函数设置为None\n",
    "        y=inference(x,None)\n",
    "        \n",
    "        #使用前向传播的结果计算准确率，如果需要对未知的样例进行分类，，俺么使用tf.argmax(y,1)就可以得到输出样例的预测类别了。\n",
    "        correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        #通过变量重命名的方式来加载模型，这样在前向传播过程中，就不需要调用滑动平均的函数来获取平均值，这样就可以完全公用前面的前向传播过程。\n",
    "        variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore=variable_averages.variables_to_restore()\n",
    "        saver=tf.train.Saver(variables_to_restore)\n",
    "        while True:\n",
    "            with tf.Session() as sess:\n",
    "                ckpt=tf.train.get_checkpoint_state(MODEL_SAVE_PATH)\n",
    "                if(ckpt and ckpt.model_checkpoint_path):\n",
    "                    #加载模型\n",
    "                    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "                    #通过文件名保存模型保存时迭代的轮次\n",
    "                    global_step=ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "                    accuracy_score=sess.run(accuracy,feed_dict=validate_feed)\n",
    "                    print(\"After %s training step(s),validation accuracy=%g \" % (global_step,accuracy_score))\n",
    "                else:\n",
    "                    print(\"No ckickpoint file found\")\n",
    "                    return\n",
    "                time.sleep(EVAL_INTERVAL_SECS)\n",
    "def main(argv=None):\n",
    "    mnist=input_data.read_data_sets(\"/path/to/MNIST_data/\",one_hot=True)\n",
    "    evaluate(mnist)\n",
    "if __name__=='__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
