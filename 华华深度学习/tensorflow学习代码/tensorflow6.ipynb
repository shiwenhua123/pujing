{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow实现一个卷积层的前向传播过程\n",
    "通过tf.get_variable的方式创建过滤器的权重和偏置项变量。上面介绍了卷集层的参数个数只和过滤器的尺寸、深度以及当前层节点的矩阵的深度有关，所以这里声明的参数变量是一个四维矩阵，前面两个代表了过滤器的尺寸，第三个维度表示当前层的深度，第四个维度表示过滤器的深度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "filter_weigths=tf.get_variable('weigths',[5,5,3,16],initializer=tf.truncated_normal_initializer(stddev=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和卷集层的权重类似，当前矩阵上不同位置的偏置项也是共享的，所以总共有下一层深度个数不同的偏置项。本样例代码中的16为过滤器的深度，也是神经网络中下一层节点矩阵的深度."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases=tf.get_variable('biases',shape=[16],initializer=tf.constant_initializer(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.conv2d提供了一个非常方便的函数来实现卷积层向前传播的算法。这个函数的第一个输入为当前层的节点矩阵。注意这个矩阵是一个四维矩阵，后面三个维度对应一个节点矩阵，第一维对应一个输入batch。比如在输入层，input[0,:,:,:]表示第一张图片，input[1,:,:,:]表示第二张图片，以此类推。tf.nn.conv2d第二个参数提供了卷集层的权重，第三个参数为不同维度上的步长，虽然第三个参数提供了一个长度为4的数组，但是第一维和最后一维的数字要求一定是1。这是因为卷积层的步长只对矩阵的长宽有效。最后一个参数是填充的方法，Tensorflow中提供SAME和VALID两种选择，其中SAME表示添加全0填充，VALID表示不添加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv=tf.nn.conv2d(input,filter_weigths,strides=[1,1,1,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.bias_add提供了一个方便的函数给每个节点加上偏置项，注意这里不能直接使用加法，因为矩阵上不同位置上的节点都需要加上同样的偏置项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias=tf.nn.bias_add(conv,biases)\n",
    "#将计算结果通过relu函数完成去线性化\n",
    "active_conv=tf.nn.relu(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.nn.max_pool实现了最大池化层的前向传播过程，他的参数和tf.nn.conv2d函数类似\n",
    "#ksize提供了过滤器的尺寸，strides提供了步长信息，padding提供了是否用全0填充。\n",
    "pool=tf.nn.max_pool(actived_conv,ksize=[1,3,3,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BATCH_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0245ab337b68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;31m#调整输入数据placeholder的格式，输入为一个四维矩阵\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_CHANNELS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'x_input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;31m#类似地将输入的格式调整为4维，并将这个调整后的数据传入sess.run过程\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreshaped_xs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_CHANNELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BATCH_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#调整输入数据placeholder的格式，输入为一个四维矩阵\n",
    "x=tf.placeholder(tf.float32,[BATCH_SIZE,IMAGE_SIZE,IMAGE_SIZE,NUM_CHANNELS],name='x_input')\n",
    "#类似地将输入的格式调整为4维，并将这个调整后的数据传入sess.run过程\n",
    "reshaped_xs=np.reshape(xs,(BATCH_SIZE,IMAGE_SIZE,IMAGE_SIZE,NUM_CHANNELS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#配置神经网络的参数\n",
    "INPUT_NODE=784\n",
    "OUTPUT_NODE=10\n",
    "\n",
    "IMAGE_SIZE=28\n",
    "NUM_CHANNELS=1\n",
    "NUM_LABELS=10\n",
    "\n",
    "#第一层卷积层的尺寸和深度\n",
    "CONV1_DEEP=32\n",
    "CONV1_SIZE=5\n",
    "\n",
    "#第二层卷积层的尺寸和深度\n",
    "CONV2_DEEP=64\n",
    "CONV2_SIZE=5\n",
    "\n",
    "#全连接层的节点个数\n",
    "FC_SIZE=512\n",
    "\n",
    "#定义卷积神经网络的前向传播过程，这里面添加了一个新的参数train,用于区分训练过程和测试过程这个过程中\n",
    "#用到dropout方法，dropout可以进一步提升模型的可靠性并防止过拟合，dropout过程只在训练时使用\n",
    "\n",
    "def inference(input_tensor,train,regularizer):\n",
    "    #声明第一层的变量并实现前向传播过程\n",
    "    #通过使用不同的命名空间来隔离不同层的变量\n",
    "    #这样可以让每一层中的变量命名只需要考虑当前层的作用，而不需要担心重命名的问题\n",
    "    #这里定义的卷积层输入为28*28*1的原始MNIST图片像素。\n",
    "    #因为卷积层中使用了全0填充，所以输出为28*28*32的矩阵\n",
    "    with tf.variable_scope('layer1-conv1'):\n",
    "        conv1_weigths=tf.get_variable(\"weigths\",[CONV1_SIZE,CONV1_SIZE,NUM_CHANNELS,CONV1_DEEP],initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        conv1_biases=tf.get_variable(\"bias\",[CONV1_DEEP],initializer=tf.constant_initializer(0.0))\n",
    "        #使用边长为5，深度为37的过滤器，过滤移动的步长为1，且使用全零补充\n",
    "        conv1=tf.nn.conv2d(input_tensor,conv1_weigths,strides=[1,1,1,1],padding='SAME')\n",
    "        relu1=tf.nn.relu(tf.nn.bias_add(conv1,conv1_biases))\n",
    "        \n",
    "        #实现第二层池化层的前向传播过程。这里选用最大池化层，池化层过滤器的边长为2，，使用全零补充并且移动的步长为2\n",
    "        #这一层的输入是上一层的输出，也就是28*28*32的矩阵\n",
    "        #输出为14*14*32的矩阵\n",
    "    with tf.name_scope('layer2-pool1'):\n",
    "        pool1=tf.nn.max_pool(relu1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "            \n",
    "    #声明第三层的卷积层的变量并实现前向传播过程，这一层的输入为14*14*32的矩阵\n",
    "    #输出为14*14*64的矩阵\n",
    "    with tf.variable_scope('layer-conv2'):\n",
    "        conv2_weigths=tf.get_variable(\"weigths\",[CONV2_SIZE,CONV2_SIZE,CONV1_DEEP,CONV2_DEEP],initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        conv2_biases=tf.get_variable(\"bias\",[CONV2_DEEP],initializer=tf.constant_initializer(0.0))\n",
    "        #使用边长为5，深度为64的过滤器，过滤移动的步长为1，且使用全零补充。\n",
    "        conv2=tf.nn.conv2d(pool1,conv2_weigths,strides=[1,1,1,1],padding='SAME')\n",
    "        relu2=tf.nn.relu(tf.nn.bias_add(conv2,conv2_biases))\n",
    "            \n",
    "    #实现第四层池化层的前向传播过程，第一层和第二层的结构是一样的，这一层的输入为14*14*64的矩阵，输出为7*7*64的矩阵。\n",
    "    with tf.name_scope('layer4_pool2'):\n",
    "        pool2=tf.nn.max_pool(relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    #将第四层池化层的输出转化为第五层全连接层的输入格式，第四层的输出为7*7*64的矩阵，然而\n",
    "    #第五层的全连接层需要的输入格式为向量，所以这里需要将这个7*7*64的矩阵拉成一个向量\n",
    "    #pool2.get_shape()函数可以得到第四层输出矩阵的维度而不需要手工计算。\n",
    "    #注意，因为每一层神经网络的输入输出都为一个batch的矩阵，所以这里得到的维度包含一个batch中数据的个数\n",
    "    pool_shape=pool2.get_shape().as_list()\n",
    "        \n",
    "    #计算将矩阵拉直成向量之后的长度，这个长度就是矩阵长宽以及深度的乘积\n",
    "    nodes=pool_shape[1]*pool_shape[2]*pool_shape[3]\n",
    "    #通过tf.reshape函数将第四层的输出变成一个batch的向量\n",
    "    reshaped=tf.reshape(pool2,[pool_shape[0],nodes])\n",
    "        \n",
    "    #第五层全连接层\n",
    "    with tf.variable_scope('layer5-fcl'):\n",
    "        fcl_weights=tf.get_variable(\"weight\",[nodes,FC_SIZE],initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        #只有全连接层的权重需要加入正则化\n",
    "        if(regularizer!=None):\n",
    "            tf.add_to_collection('losses',regularizer(fcl_weights))\n",
    "        fcl_biases=tf.get_variable(\"bias\",[FC_SIZE],initializer=tf.constant_initializer(0.1))\n",
    "        fcl=tf.nn.relu(tf.matmul(reshaped,fcl_weights)+fcl_biases)\n",
    "        if(train):\n",
    "            fcl=tf.nn.dropout(fcl,0.5)\n",
    "        #声明第六层变量并实现全连接层的前向传播结果。\n",
    "    with tf.variable_scope('layer6-fc2'):\n",
    "        fc2_weights=tf.get_variable(\"weight\",[FC_SIZE,NUM_LABELS],initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        if(regularizer!=None):\n",
    "            tf.add_to_collection('losses',regularizer(fcl_weights))\n",
    "        fc2_biases=tf.get_variable(\"bias\",[NUM_LABELS],initializer=tf.constant_initializer(0.1))\n",
    "        logit=tf.matmul(fcl,fc2_weights)+fc2_biases\n",
    "    return logit\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /path/to/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-2-7fb68e5d7cff>:56: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "After 1 training step(s),loss on training batch is 6.60094.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#配置神经网络参数\n",
    "BATCH_SIZE=100\n",
    "LEARNING_RATE_BASE=0.8   #基础学习率\n",
    "LEARNING_RATE_DECAY=0.99     #学习率的衰减率\n",
    "REGULARAZTION_RATE=0.0001  #描述模型复杂度的正则化项在损失函数中的系数\n",
    "TRAINING_STEPS=5000       #训练次数\n",
    "MOVING_AVERAGE_DECAY=0.99     #滑动平均衰减率\n",
    "\n",
    "#模型保存的路径和文件名\n",
    "MODEL_SAVE_PATH=\"/path/to/model/\"\n",
    "MODEL_NAME=\"model.ckpt\"\n",
    "\n",
    "\n",
    "def train(mnist):\n",
    "    # 定义输出为4维矩阵的placeholder\n",
    "    x = tf.placeholder(tf.float32, [\n",
    "            BATCH_SIZE,\n",
    "            IMAGE_SIZE,\n",
    "            IMAGE_SIZE,\n",
    "            NUM_CHANNELS],\n",
    "        name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None,OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    #L2正则化损失函数\n",
    "    regularizer=tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n",
    "    #直接使用前向传播算法\n",
    "    y=inference(x,False,regularizer)\n",
    "    #定义训练轮次的变量\n",
    "    global_step=tf.Variable(0,trainable=False)\n",
    "    \n",
    "    #接下来定义损失函数，学习率，滑动平均值，以及训练过程\n",
    "    variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)\n",
    "    variable_averages_op=variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    #交叉熵\n",
    "    cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,1))\n",
    "    cross_entropy_mean=tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    #总损失\n",
    "    loss=cross_entropy_mean+tf.add_n(tf.get_collection('losses'))\n",
    "    \n",
    "    #设置学习率和优化损失函数\n",
    "    learning_rate=tf.train.exponential_decay(LEARNING_RATE_BASE,global_step,mnist.train.num_examples/BATCH_SIZE,LEARNING_RATE_DECAY)\n",
    "    train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step)\n",
    "    with tf.control_dependencies([train_step,variable_averages_op]):\n",
    "        train_op=tf.no_op(name='train')\n",
    "        \n",
    "    #初始化持久化类\n",
    "    saver=tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "            reshaped_xs = np.reshape(xs, (\n",
    "                BATCH_SIZE,\n",
    "                IMAGE_SIZE,\n",
    "                IMAGE_SIZE,\n",
    "                NUM_CHANNELS))\n",
    "            _,loss_value,step=sess.run([train_op,loss,global_step],feed_dict={x:reshaped_xs,y_:ys})\n",
    "            \n",
    "            #每1000轮保存一次模型\n",
    "            if(i%1000==0):\n",
    "                print(\"After %d training step(s),loss on training batch is %g.\" %(step,loss_value))\n",
    "                saver.save(sess,os.path.join(MODEL_SAVE_PATH,MODEL_NAME),global_step=global_step)\n",
    "\n",
    "def main(argv=None):\n",
    "    mnist=input_data.read_data_sets(\"/path/to/MNIST_data/\",one_hot=True)\n",
    "    train(mnist)\n",
    "if __name__=='__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 卷积神经网络手写数字识别系统最佳实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#构建LeNet-5模型结构的前向传播过程\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#配置神经网络的参数\n",
    "INPUT_NODE=784\n",
    "OUTPUT_NODE=10\n",
    "\n",
    "IMAGE_SIZE=28\n",
    "NUM_CHANNELS=1\n",
    "NUM_LABELS=10\n",
    "\n",
    "#第一层卷积层的尺寸和深度\n",
    "CONV1_DEEP=32\n",
    "CONV1_SIZE=5\n",
    "#第二层的尺寸和深度\n",
    "CONV2_DEEP=64\n",
    "CONV2_SIZE=5\n",
    "#全连接层的节点个数\n",
    "FC_SIZE=512\n",
    "\n",
    "def inference(input_tensor,train,regularizer):\n",
    "    with tf.variable_scope('layer1-conv1'):\n",
    "        conv1_weights=tf.get_variable(\"weights\",[CONV1_SIZE,CONV1_SIZE,NUM_CHANNELS,CONV1_DEEP],initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        conv1_biases=tf.get_variable(\"bias\",[CONV1_DEEP],initializer=tf.constant_initializer(0.0))\n",
    "        conv1=tf.nn.conv2d(input_tensor,conv1_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu1=tf.nn.relu(tf.nn.bias_add(conv1,conv1_biases))\n",
    "    with tf.variable_scope('layer2-pool1'):\n",
    "        pool1=tf.nn.max_pool(relu1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    with tf.variable_scope('layer3-conv2'):\n",
    "        conv2_weights=tf.get_variable(\"weights\",[CONV2_SIZE,CONV2_SIZE,CONV1_DEEP,CONV2_DEEP],initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        conv2_biases=tf.get_variable(\"bias\",[CONV2_DEEP],initializer=tf.constant_initializer(0.0))\n",
    "        conv2=tf.nn.conv2d(pool1,conv2_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu2=tf.nn.relu(tf.nn.bias_add(conv2,conv2_biases))\n",
    "    with tf.variable_scope('layer4-pool2'):\n",
    "        pool2=tf.nn.max_pool(relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "   \n",
    "    pool1_shape=pool2.get_shape().as_list()\n",
    "    nodes=pool1_shape[1]*pool1_shape[2]*pool1_shape[3]\n",
    "    reshape=tf.reshape(pool2,[pool1_shape[0],nodes])\n",
    "    \n",
    "    with tf.variable_scope('layer5-fc1'):\n",
    "        fc1_weights=tf.get_variable(\"weights\",[nodes,FC_SIZE],initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        #只有全连接层才需要加入正则化\n",
    "        if(regularizer!=None):\n",
    "            tf.add_to_collection('losses',regularizer(fc1_weights))\n",
    "        fc1_biases=tf.get_variable(\"bias\",[FC_SIZE],initializer=tf.constant_initializer(0.1))\n",
    "        fc1=tf.nn.relu(tf.matmul(reshape,fc1_weights)+fc1_biases)\n",
    "        if(train):\n",
    "            fc1=tf.nn.dropout(fc1,0.5)\n",
    "    with tf.variable_scope('layer5-fc2'):\n",
    "        fc2_weights=tf.get_variable(\"weights\",[FC_SIZE,NUM_LABELS],initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        if(regularizer!=None):\n",
    "            tf.add_to_collection('losses',regularizer(fc2_weights))\n",
    "        fc2_biases=tf.get_variable(\"bias\",[NUM_LABELS],initializer=tf.constant_initializer(0.1))\n",
    "        logit=tf.matmul(fc1,fc2_weights)+fc2_biases\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#构建LeNet-5模型结构的训练过程\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#配置神经网络的参数\n",
    "BATCH_SIZE=100\n",
    "LEARNING_RATE_BASE=0.8    #基础的学习率\n",
    "LEARNING_RATE_DECAY=0.99     #学习率的衰减率\n",
    "REGULARAZTION_RATE=0.0001    #描述模型复杂度的正则化项在损失函数中的系数\n",
    "TRAINING_STEP=5000           #训练轮次\n",
    "MOVING_AVERAGE_DECAY=0.99     #滑动平均衰减率\n",
    "#模型保存的路径和文件名\n",
    "MODEL_SAVE_PATH=\"/path/Tensorflow/6/\"\n",
    "MODEL_NAME=\"model.ckpt\"\n",
    "def train(mnist):\n",
    "    #定义输入输出placeholder\n",
    "    x=tf.placeholder(tf.float32,[BATCH_SIZE,IMAGE_SIZE,IMAGE_SIZE,NUM_CHANNELS],name='X_input')\n",
    "    y_=tf.placeholder(tf.float32,[None,OUTPUT_NODE],name='y_input')\n",
    "    regularizer=tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n",
    "    y=inference(x,False,regularizer)\n",
    "    global_step=tf.Variable(0,trainable=False)\n",
    "    \n",
    "    #定义损失函数、学习率、滑动平均操作以及训练过程\n",
    "    variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)\n",
    "    variable_averages_op=variable_averages.apply(tf.trainable_variables())\n",
    "    cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,1))\n",
    "    cross_entropy_mean=tf.reduce_mean(cross_entropy)\n",
    "    loss=cross_entropy_mean+tf.add_n(tf.get_collection('losses'))\n",
    "    learning_rate=tf.train.exponential_decay(LEARNING_RATE_BASE,global_step,mnist.train.num_examples/BATCH_SIZE,LEARNING_RATE_DECAY,staircase=True)\n",
    "    train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "    with tf.control_dependencies([train_step,variable_averages_op]):\n",
    "        train_op=tf.no_op(name='train')\n",
    "    \n",
    "    #初始化Tensorflow持久化类\n",
    "    saver=tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for i in range(TRAINING_STEP):\n",
    "            xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "            reshaped_xs=np.reshape(xs,(BATCH_SIZE,IMAGE_SIZE,IMAGE_SIZE,NUM_CHANNELS))\n",
    "            _,loss_value,step=sess.run([train_op,loss,global_step],feed_dict={x:reshaped_xs,y_:ys})\n",
    "            \n",
    "            if(i%1000==0):\n",
    "                print(\"After %d training step(s),loss on training batch is %g.\" %(step,loss_value))\n",
    "                saver.save(sess,os.path.join(MODEL_SAVE_PATH,MODEL_NAME),global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /path/to/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "After 1 training step(s),loss on training batch is 4.2587.\n",
      "After 1001 training step(s),loss on training batch is 17.4877.\n",
      "After 2001 training step(s),loss on training batch is 15.2794.\n",
      "After 3001 training step(s),loss on training batch is 13.4302.\n",
      "After 4001 training step(s),loss on training batch is 11.867.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    mnist=input_data.read_data_sets(\"/path/to/MNIST_data/\",one_hot=True)\n",
    "    train(mnist)\n",
    "if __name__=='__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "EVAL_INTERVAL_SECS=10\n",
    "def evaluate(mnist):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        #定义输入输出placeholder\n",
    "        x=tf.placeholder(tf.float32,[mnist.validation.num_examples,IMAGE_SIZE,IMAGE_SIZE,NUM_CHANNELS],name='X_input')\n",
    "        y_=tf.placeholder(tf.float32,[None,OUTPUT_NODE],name='y_input')\n",
    "        \n",
    "        xs,ys=mnist.validation.next_batch(mnist.validation.num_examples)\n",
    "        \n",
    "        reshaped_xs=np.reshape(xs,(mnist.validation.num_examples,IMAGE_SIZE,IMAGE_SIZE,NUM_CHANNELS))\n",
    "        validate_feed={x:reshaped_xs,y_:mnist.validation.labels}\n",
    "        \n",
    "        y=inference(x,False,None)\n",
    "        correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore=variable_averages.variables_to_restore()\n",
    "        saver=tf.train.Saver(variables_to_restore)\n",
    "        while True:\n",
    "            with tf.Session() as sess:\n",
    "                ckpt=tf.train.get_checkpoint_state(MODEL_SAVE_PATH)\n",
    "                if(ckpt and ckpt.model_checkpoint_path):\n",
    "                    #加载模型\n",
    "                    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "                    #通过文件名保存模型保存时迭代的轮次\n",
    "                    global_step=ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "                    accuracy_score=sess.run(accuracy,feed_dict=validate_feed)\n",
    "                    print(\"After %s training step(s),validation accuracy=%g \" % (global_step,accuracy_score))\n",
    "                else:\n",
    "                    print(\"No ckickpoint file found\")\n",
    "                    return\n",
    "                time.sleep(EVAL_INTERVAL_SECS)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /path/to/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 4 but is rank 5 for 'layer1-conv1/Conv2D' (op: 'Conv2D') with input shapes: [?,5000,28,28,1], [5,5,1,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    672\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 4 but is rank 5 for 'layer1-conv1/Conv2D' (op: 'Conv2D') with input shapes: [?,5000,28,28,1], [5,5,1,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8a70f8404566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-8a70f8404566>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmnist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/path/to/MNIST_data/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-669589d4e23a>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(mnist)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mvalidate_feed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mreshaped_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ca6d44dc0ad2>\u001b[0m in \u001b[0;36minference\u001b[0;34m(input_tensor, train, regularizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mconv1_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCONV1_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCONV1_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_CHANNELS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCONV1_DEEP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mconv1_biases\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bias\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCONV1_DEEP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mconv1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconv1_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mrelu1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconv1_biases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'layer2-pool1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    404\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    766\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    767\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2336\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2337\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1717\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\pujing\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 4 but is rank 5 for 'layer1-conv1/Conv2D' (op: 'Conv2D') with input shapes: [?,5000,28,28,1], [5,5,1,32]."
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    mnist=input_data.read_data_sets(\"/path/to/MNIST_data/\",one_hot=True)\n",
    "    evaluate(mnist)\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "INPUT_NODE = 784\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "NUM_LABELS = 10\n",
    "\n",
    "CONV1_DEEP = 32\n",
    "CONV1_SIZE = 5\n",
    "\n",
    "CONV2_DEEP = 64\n",
    "CONV2_SIZE = 5\n",
    "\n",
    "FC_SIZE = 512\n",
    "\n",
    "def inference(input_tensor, train, regularizer):\n",
    "    with tf.variable_scope('layer1-conv1'):\n",
    "        conv1_weights = tf.get_variable(\n",
    "            \"weight\", [CONV1_SIZE, CONV1_SIZE, NUM_CHANNELS, CONV1_DEEP],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        conv1_biases = tf.get_variable(\"bias\", [CONV1_DEEP], initializer=tf.constant_initializer(0.0))\n",
    "        conv1 = tf.nn.conv2d(input_tensor, conv1_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))\n",
    "\n",
    "    with tf.name_scope(\"layer2-pool1\"):\n",
    "        pool1 = tf.nn.max_pool(relu1, ksize = [1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "    with tf.variable_scope(\"layer3-conv2\"):\n",
    "        conv2_weights = tf.get_variable(\n",
    "            \"weight\", [CONV2_SIZE, CONV2_SIZE, CONV1_DEEP, CONV2_DEEP],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        conv2_biases = tf.get_variable(\"bias\", [CONV2_DEEP], initializer=tf.constant_initializer(0.0))\n",
    "        conv2 = tf.nn.conv2d(pool1, conv2_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))\n",
    "\n",
    "    with tf.name_scope(\"layer4-pool2\"):\n",
    "        pool2 = tf.nn.max_pool(relu2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        pool_shape = pool2.get_shape().as_list()\n",
    "        nodes = pool_shape[1] * pool_shape[2] * pool_shape[3]\n",
    "        reshaped = tf.reshape(pool2, [pool_shape[0], nodes])\n",
    "\n",
    "    with tf.variable_scope('layer5-fc1'):\n",
    "        fc1_weights = tf.get_variable(\"weight\", [nodes, FC_SIZE],\n",
    "                                      initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        if regularizer != None: tf.add_to_collection('losses', regularizer(fc1_weights))\n",
    "        fc1_biases = tf.get_variable(\"bias\", [FC_SIZE], initializer=tf.constant_initializer(0.1))\n",
    "\n",
    "        fc1 = tf.nn.relu(tf.matmul(reshaped, fc1_weights) + fc1_biases)\n",
    "        if train: fc1 = tf.nn.dropout(fc1, 0.5)\n",
    "\n",
    "    with tf.variable_scope('layer6-fc2'):\n",
    "        fc2_weights = tf.get_variable(\"weight\", [FC_SIZE, NUM_LABELS],\n",
    "                                      initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        if regularizer != None: tf.add_to_collection('losses', regularizer(fc2_weights))\n",
    "        fc2_biases = tf.get_variable(\"bias\", [NUM_LABELS], initializer=tf.constant_initializer(0.1))\n",
    "        logit = tf.matmul(fc1, fc2_weights) + fc2_biases\n",
    "\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE_BASE = 0.01\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "TRAINING_STEPS = 6000\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "\n",
    "MODEL_SAVE_PATH=\"/path/Tensorflow/7/\"\n",
    "MODEL_NAME=\"model.ckpt\"\n",
    "\n",
    "def train(mnist):\n",
    "    # 定义输出为4维矩阵的placeholder\n",
    "    x = tf.placeholder(tf.float32, [\n",
    "            BATCH_SIZE,\n",
    "            IMAGE_SIZE,\n",
    "            IMAGE_SIZE,\n",
    "            NUM_CHANNELS],\n",
    "        name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    y =inference(x,False,regularizer)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # 定义损失函数、学习率、滑动平均操作以及训练过程。\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    loss = cross_entropy_mean + tf.add_n(tf.get_collection('losses'))\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        mnist.train.num_examples / BATCH_SIZE, LEARNING_RATE_DECAY,\n",
    "        staircase=True)\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "        \n",
    "    # 初始化TensorFlow持久化类。\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "\n",
    "            reshaped_xs = np.reshape(xs, (\n",
    "                BATCH_SIZE,\n",
    "                IMAGE_SIZE,\n",
    "                IMAGE_SIZE,\n",
    "                NUM_CHANNELS))\n",
    "            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: reshaped_xs, y_: ys})\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(\"After %d training step(s), loss on training batch is %g.\" % (step, loss_value))\n",
    "                saver.save(sess,os.path.join(MODEL_SAVE_PATH,MODEL_NAME),global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /path/to/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "After 1 training step(s), loss on training batch is 4.3068.\n",
      "After 1001 training step(s), loss on training batch is 0.681441.\n",
      "After 2001 training step(s), loss on training batch is 0.736585.\n",
      "After 3001 training step(s), loss on training batch is 0.699708.\n",
      "After 4001 training step(s), loss on training batch is 0.657589.\n",
      "After 5001 training step(s), loss on training batch is 0.709574.\n"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    mnist=input_data.read_data_sets(\"/path/to/MNIST_data/\",one_hot=True)\n",
    "    train(mnist)\n",
    "if __name__=='__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "EVAL_INTERVAL_SECS=10\n",
    "def evaluate(mnist):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        #定义输入输出placeholder\n",
    "        x=tf.placeholder(tf.float32,[mnist.validation.num_examples,IMAGE_SIZE,IMAGE_SIZE,NUM_CHANNELS],name='X_input')\n",
    "        y_=tf.placeholder(tf.float32,[None,OUTPUT_NODE],name='y_input')\n",
    "        \n",
    "        xs,ys=mnist.validation.next_batch(mnist.validation.num_examples)\n",
    "        \n",
    "        reshaped_xs=np.reshape(xs,(mnist.validation.num_examples,IMAGE_SIZE,IMAGE_SIZE,NUM_CHANNELS))\n",
    "        validate_feed={x:reshaped_xs,y_:mnist.validation.labels}\n",
    "        \n",
    "        y=inference(x,False,None)\n",
    "        correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore=variable_averages.variables_to_restore()\n",
    "        saver=tf.train.Saver(variables_to_restore)\n",
    "        while True:\n",
    "            with tf.Session() as sess:\n",
    "                ckpt=tf.train.get_checkpoint_state(MODEL_SAVE_PATH)\n",
    "                if(ckpt and ckpt.model_checkpoint_path):\n",
    "                    #加载模型\n",
    "                    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "                    #通过文件名保存模型保存时迭代的轮次\n",
    "                    global_step=ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "                    accuracy_score=sess.run(accuracy,feed_dict=validate_feed)\n",
    "                    print(\"After %s training step(s),validation accuracy=%g \" % (global_step,accuracy_score))\n",
    "                else:\n",
    "                    print(\"No ckickpoint file found\")\n",
    "                    return\n",
    "                time.sleep(EVAL_INTERVAL_SECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    mnist=input_data.read_data_sets(\"/path/to/MNIST_data/\",one_hot=True)\n",
    "    evaluate(mnist)\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tensorflow实现迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inception-v3模型瓶颈层的节点个数\n",
    "BOTTLENECK_TENSOR_SIZE=2048\n",
    "\n",
    "#Inception-v3模型中代表瓶颈层结构的张量名称\n",
    "# 在谷歌提出的Inception-v3模型中，这个张量名称就是'pool_3/_reshape:0'。\n",
    "# 在训练模型时，可以通过tensor.name来获取张量的名称。\n",
    "BOTTLENECK_TENSOR_NAME='pool_3/_reshape:0'\n",
    "\n",
    "#图像输入张量对应的名称\n",
    "JPEG_DATA_TENSOR_NAME='DecodeJpeg/contents:0'\n",
    "\n",
    "#下载的谷歌训练好的Inception-v3模型文件目录\n",
    "MODEL_DIR='model/'\n",
    "\n",
    "#下载的谷歌训练好的Inception-v3模型文件名\n",
    "MODEL_FILE='tensorflow_inception_graph.pb'\n",
    "\n",
    "#因为一个训练数据可能会被使用多次，所以可以将原图像通过Inception-v3模型计算得到的特征向量保存在文\n",
    "#件中，免去重复计算\n",
    "#下面定义了这些文件的存放地址。\n",
    "CACHE_DIR='tmp/bottleneck/'\n",
    "\n",
    "\n",
    "#图片数据文件夹\n",
    "#在这个文件夹中每个子文件夹代表一个需要区分的类别，每个子文件夹中存放了对应类别的图片\n",
    "INPUT_DATA='flower_data'\n",
    "\n",
    "#验证的数据百分比\n",
    "VALIDATION_PERCENTAGE=10\n",
    "\n",
    "#测试数据的百分比\n",
    "TEST_PERCENTAGE=10\n",
    "\n",
    "#定义神经网络的设置\n",
    "\n",
    "LEARNING_RATE=0.01\n",
    "STEPS=4000\n",
    "BATCH=100\n",
    "\n",
    "#这个函数从数据文件夹中读取所有的图片列表并按照训练验证测试数据分开\n",
    "#testing_percentage和yalidation_perdation_percentage参数指定了测试数据集合验证数据集的大小\n",
    "def create_image_lists(testing_percentage,validation_perecentage):\n",
    "    #得到的所有图片都存在result这个字典里\n",
    "    #这个字典的key为类别的名称，value也是一个字典，字典里存储了所有图片名称。\n",
    "    result={}\n",
    "    #获取当前名录下所有的子目录\n",
    "    sub_dirs=[x[0] for x in os.walk(INPUT_DATA)]\n",
    "    \n",
    "    #得到的第一个目录是当前目录不需要考虑\n",
    "    is_root_dir=True\n",
    "    for sub_dir in sub_dirs:\n",
    "        if(is_root_dir):\n",
    "            is_root_dir=False\n",
    "            continue\n",
    "        #获取当前目录下所有的有效图片文件\n",
    "        extensions=['jpg','jpeg','JPG','JPEG']\n",
    "        file_list=[]\n",
    "        dir_name=os.path.basename(sub_dir)\n",
    "        for extension in extensions:\n",
    "            file_glob=os.path.join(INPUT_DATA,dir_name,'*.'+extension)\n",
    "            file_list.extend(glob.glob(file_glob))\n",
    "        if not file_list:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
