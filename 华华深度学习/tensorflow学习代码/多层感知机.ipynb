{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层感知器\n",
    "多层感知器（神经网络）实现示例使用\n",
    "TensorFlow库。 这个例子是使用手写的MNIST数据库\n",
    "数字（http://yann.lecun.com/exdb/mnist/）。\n",
    "链接：\n",
    "     [MNIST数据集]（http://yann.lecun.com/exdb/mnist/）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets(\"/tmp/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#参数设置\n",
    "learning_rate=0.001\n",
    "training_epochs=20\n",
    "batch_size=100\n",
    "display_step=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#神经网络参数设置\n",
    "n_hidden_1=256\n",
    "n_hidden_2=256\n",
    "n_input=784\n",
    "n_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#计算图的输入\n",
    "X=tf.placeholder(tf.float32,[None,n_input],name=\"x_input\")\n",
    "Y=tf.placeholder(tf.float32,[None,n_classes],name=\"y_input\")\n",
    "\n",
    "#存储神经网络层的权重和偏差\n",
    "weights={\n",
    "    'h1':tf.Variable(tf.random_normal([n_input,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2,n_classes]))}\n",
    "biases={\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "#创建神经网络模型\n",
    "def multilayer_perceptron(x):\n",
    "    #构建全连接层的前向传播过程\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    out_layer=tf.matmul(layer_2,weights['out'])+biases['out']\n",
    "    return out_layer\n",
    "\n",
    "#构建模型\n",
    "logits=multilayer_perceptron(X)\n",
    "#定义损失函数和梯度下降过程\n",
    "loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y))\n",
    "train_op=tf.train.AdamOptimizer(learning_rate).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 cost=331.979575507\n",
      "Epoch 0002 cost=101.647568574\n",
      "Epoch 0003 cost=75.717219445\n",
      "Epoch 0004 cost=60.329107638\n",
      "Epoch 0005 cost=51.487579248\n",
      "Epoch 0006 cost=45.324585719\n",
      "Epoch 0007 cost=40.116811979\n",
      "Epoch 0008 cost=35.662131152\n",
      "Epoch 0009 cost=32.932886932\n",
      "Epoch 0010 cost=30.074609101\n",
      "Epoch 0011 cost=28.295875002\n",
      "Epoch 0012 cost=26.487894574\n",
      "Epoch 0013 cost=24.776589068\n",
      "Epoch 0014 cost=23.164681619\n",
      "Epoch 0015 cost=21.760461151\n",
      "Epoch 0016 cost=20.782326303\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost=0\n",
    "        total_batch=int(mnist.train.num_examples/batch_size)\n",
    "        #循环遍历所有batch\n",
    "        for i in range(total_batch):\n",
    "            batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "            #运行优化op（backprop）和cost op（获取损失值）\n",
    "            _,c=sess.run([train_op,loss_op],feed_dict={X:batch_x,Y:batch_y})\n",
    "            #计算平均损失\n",
    "            avg_cost+=c/total_batch\n",
    "        if(epoch % display_step==0):\n",
    "            print(\"Epoch\",'%04d' % (epoch+1),\"cost={:.9f}\".format(avg_cost))\n",
    "    print(\"Potimization Finished\")\n",
    "    \n",
    "    #测试模型\n",
    "    pred=tf.nn.softmax(logits)\n",
    "    correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(Y,1))\n",
    "    #计算准确率\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    print(\"Accuracy:\",accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
